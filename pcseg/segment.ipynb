{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import open3d as o3d\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/biophys/schimmenti/Repositories/single-cell-analysis-of-organoids/measurements/point_cloud_approach/'\n",
    "data_dir = '/Users/schimmenti/Desktop/DresdenProjects/Organoids/single-cell-analysis-of-organoids/measurements/point_cloud_approach/'\n",
    "annotation_json = data_dir + 'annotations_DD.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24690da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(annotation_json) as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for file_key, anns in annotations.items():\n",
    "    pc_filename = data_dir + file_key\n",
    "    points = np.asarray(o3d.io.read_point_cloud(pc_filename).points)\n",
    "    identifier = file_key.split('/')[-1].split('.ply')[0]\n",
    "    dataset[identifier] = {'points': points, 'annotations': np.array(anns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_dataset = {}\n",
    "for file in Path(data_dir).joinpath('point_clouds_OO/').glob('*.ply'):\n",
    "    points = np.asarray(o3d.io.read_point_cloud(file.absolute()).points)\n",
    "    identifier = file.name.split('.ply')[0]\n",
    "    unlabelled_dataset[identifier] = {'points': points, 'annotations': np.full(len(points), -1, dtype=int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a452693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph, SAGEConv\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.data import InMemoryDataset, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import math, random\n",
    "from torch.utils.data import Dataset as _TorchDataset\n",
    "\n",
    "def build_edge_labelled_knn_graph(points, point_labels, k):\n",
    "    \"\"\"\n",
    "    points: (N, d) float32 array/tensor with XYZ (or 2D) coords\n",
    "    point_labels: (N,) int/bool per-node annotations\n",
    "        Example rule below sets edge_label=1 if endpoints share the same node label.\n",
    "        Swap the rule to match your own definition.\n",
    "\n",
    "    Returns a PyG Data with:\n",
    "      - pos, x (=pos as default), edge_index\n",
    "      - edge_label_index (== edge_index)\n",
    "      - edge_label (E,)\n",
    "      - train/val/test masks over edges\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(points): points = torch.tensor(points, dtype=torch.float32)\n",
    "    if not torch.is_tensor(point_labels): point_labels = torch.tensor(point_labels)\n",
    "\n",
    "    pos = points\n",
    "    x   = pos  # or replace with your point features (N, F)\n",
    "\n",
    "    # kNN graph\n",
    "    edge_index = knn_graph(x=pos, k=k, loop=False)\n",
    "    edge_index = to_undirected(edge_index, num_nodes=pos.size(0))\n",
    "    src, dst = edge_index\n",
    "    edge_label = (point_labels[src] == point_labels[dst]).to(torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        edge_vec = pos[dst] - pos[src]\n",
    "        edge_len = torch.linalg.norm(edge_vec, dim=1, keepdim=True)  # (E,1)\n",
    "    edge_attr = torch.cat([edge_vec, edge_len], dim=1)\n",
    "\n",
    "    data = Data(\n",
    "        x=x, pos=pos, edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        edge_label=edge_label,\n",
    "        edge_label_index=edge_index, \n",
    "    )\n",
    "    return data\n",
    "class RandomRotation:\n",
    "    \"\"\"Randomly rotate 3D points about a random axis or fixed axis.\"\"\"\n",
    "    def __init__(self, angle_deg=180, axis=None, seed=None):\n",
    "        self.angle_rad = math.radians(angle_deg)\n",
    "        self.axis = None if axis is None else np.asarray(axis, dtype=float)\n",
    "        self.seed = seed\n",
    "    def __call__(self, points):\n",
    "        # Accept numpy array or torch tensor; return same type as input (torch tensor if input was torch)\n",
    "        was_torch = False\n",
    "        if 'torch' in str(type(points)):\n",
    "            was_torch = True\n",
    "            pts = points.detach().cpu().numpy()\n",
    "        else:\n",
    "            pts = np.asarray(points)\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            random.seed(self.seed)\n",
    "        angle = random.uniform(-self.angle_rad, self.angle_rad)\n",
    "        if self.axis is None:\n",
    "            axis = np.random.normal(size=3)\n",
    "        else:\n",
    "            axis = np.array(self.axis, dtype=float)\n",
    "        axis = axis / (np.linalg.norm(axis) + 1e-12)\n",
    "        ux, uy, uz = axis\n",
    "        c = math.cos(angle)\n",
    "        s = math.sin(angle)\n",
    "        R = np.array([\n",
    "            [c + ux*ux*(1-c), ux*uy*(1-c) - uz*s, ux*uz*(1-c) + uy*s],\n",
    "            [uy*ux*(1-c) + uz*s, c + uy*uy*(1-c), uy*uz*(1-c) - ux*s],\n",
    "            [uz*ux*(1-c) - uy*s, uz*uy*(1-c) + ux*s, c + uz*uz*(1-c)],\n",
    "        ])\n",
    "        rotated = pts.dot(R.T)\n",
    "        if was_torch:\n",
    "            return torch.tensor(rotated, dtype=torch.float32)\n",
    "        return rotated\n",
    "\n",
    "class PCGraphDataset(_TorchDataset):\n",
    "    \"\"\"Lightweight dataset that builds kNN graph Data objects on-the-fly.\"\"\"\n",
    "    def __init__(self, data_dict, k=6, transform=None):\n",
    "        self.keys = list(data_dict.keys())\n",
    "        self.data_dict = data_dict\n",
    "        self.k = k\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        pts = self.data_dict[key]['points']\n",
    "        labs = self.data_dict[key]['annotations']\n",
    "        # center & scale\n",
    "        centered = pts - pts.mean(axis=0)\n",
    "        centered = centered / (centered.std(axis=0) + 1e-12)\n",
    "        if self.transform is not None:\n",
    "            centered = self.transform(centered)\n",
    "        return build_edge_labelled_knn_graph(centered, labs, k=self.k)\n",
    "\n",
    "class EdgeClassifier(nn.Module):\n",
    "    \"\"\"GNN encoder + edge MLP for binary edge-label prediction.\"\"\"\n",
    "    def __init__(self, in_ch, hid=64, edge_in=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        # Node encoder: 2-layer GraphSAGE\n",
    "        self.gnn = nn.ModuleList([\n",
    "            SAGEConv(in_ch, hid),\n",
    "            SAGEConv(hid, hid)\n",
    "        ])\n",
    "        # optional projection for edge_attr (if present)\n",
    "        self.edge_attr_mlp = nn.Sequential(\n",
    "            nn.Linear(edge_in, max(8, edge_in)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(max(8, edge_in), 16),\n",
    "            nn.ReLU()\n",
    "        ) if edge_in is not None and edge_in > 0 else None\n",
    "        # Edge head: concat(h_i, h_j, |h_i-h_j|, proj(edge_attr))\n",
    "        mlp_in = 3*hid + (16 if self.edge_attr_mlp is not None else 0)\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(mlp_in, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # encode node features\n",
    "        for i, conv in enumerate(self.gnn):\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            if self.dropout > 0:\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        # edge pairs to score\n",
    "        src, dst = data.edge_label_index\n",
    "        h_i, h_j = x[src], x[dst]\n",
    "        feats = [h_i, h_j, (h_i - h_j).abs()]\n",
    "        if hasattr(data, \"edge_attr\") and data.edge_attr is not None and self.edge_attr_mlp is not None:\n",
    "            # project edge attributes before concatenation\n",
    "            e = data.edge_attr\n",
    "            # ensure shape (E, edge_in)\n",
    "            e_proj = self.edge_attr_mlp(e)\n",
    "            feats.append(e_proj)\n",
    "        z = torch.cat(feats, dim=1)\n",
    "        logit = self.edge_mlp(z).squeeze(-1)\n",
    "        return logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b492492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (concise)\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "\n",
    "k_for_nn = 12\n",
    "transform = RandomRotation(angle_deg=180, axis=None)\n",
    "pcg_dataset = PCGraphDataset(dataset, k=k_for_nn, transform=transform)\n",
    "data_ldr = PyGDataLoader(pcg_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Note: build_edge_labelled_knn_graph creates edge_attr of size 4 (vec3 + length1)\n",
    "model = EdgeClassifier(in_ch=3, hid=64, edge_in=4, dropout=0.1).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_epoch(loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_e = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        logits = model(batch)\n",
    "        labels = batch.edge_label.float().to(device)\n",
    "        loss = criterion(logits, labels)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * labels.numel()\n",
    "        total_e += labels.numel()\n",
    "    return total_loss / max(1, total_e)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            probs = torch.sigmoid(model(batch))\n",
    "            preds = (probs > 0.5).long().cpu().numpy()\n",
    "            labels = batch.edge_label.long().cpu().numpy()\n",
    "            y_pred.append(preds)\n",
    "            y_true.append(labels)\n",
    "    if len(y_true) == 0:\n",
    "        return dict(acc=0.0, prec=0.0, rec=0.0, f1=0.0)\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    prec = metrics.precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = metrics.recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = metrics.f1_score(y_true, y_pred, zero_division=0)\n",
    "    return dict(acc=acc, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "# Quick run: adjust epochs and batch_size as needed\n",
    "epochs = 100\n",
    "for ep in range(1, epochs+1):\n",
    "    loss = train_epoch(data_ldr)\n",
    "    stats = evaluate(data_ldr)\n",
    "    print(f'ep {ep:02d} loss={loss:.4f} acc={stats[\"acc\"]:.4f} f1={stats[\"f1\"]:.4f}')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c388a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and loader (batch=1 so we can map per-cloud)\n",
    "pcg_unlabel = PCGraphDataset(unlabelled_dataset, k=k_for_nn, transform=None)\n",
    "unl_ldr = PyGDataLoader(pcg_unlabel, batch_size=1, shuffle=False)\n",
    "\n",
    "# Run inference\n",
    "model.eval()\n",
    "predictions = {}\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(unl_ldr):\n",
    "        batch = batch.to(device)\n",
    "        logits = model(batch)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        # edge_label_index is (2, E)\n",
    "        edge_index = batch.edge_label_index.cpu().numpy()\n",
    "        src = edge_index[0].tolist()\n",
    "        dst = edge_index[1].tolist()\n",
    "        key = pcg_unlabel.keys[i]\n",
    "        predictions[key] = {'src': np.array(src), 'dst': np.array(dst), 'prob': np.array(probs)}\n",
    "        print(f'[{i}] {key}: edges={len(probs)} mean_prob={np.mean(probs):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f74f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "for key in predictions.keys():\n",
    "    points = unlabelled_dataset[key]['points']\n",
    "    src = predictions[key]['src']\n",
    "    dst = predictions[key]['dst']\n",
    "    probs = predictions[key]['prob']\n",
    "    pred = (probs > 0.5).astype(bool)\n",
    "    graph = nx.from_edgelist(np.vstack([src, dst]).T[pred])\n",
    "    components = list(nx.connected_components(graph))\n",
    "    labels = np.concatenate([ [c_idx]*len(components[c_idx]) for c_idx in range(len(components)) ])\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(points[:, 2], points[:, 1], points[:,0], c=labels, cmap='tab10', s=3)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
