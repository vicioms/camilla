{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import open3d as o3d\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/biophys/schimmenti/Repositories/single-cell-analysis-of-organoids/measurements/point_cloud_approach/'\n",
    "data_dir = '/Users/schimmenti/Desktop/DresdenProjects/Organoids/single-cell-analysis-of-organoids/measurements/point_cloud_approach/'\n",
    "annotation_json = data_dir + 'annotations_DD.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24690da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(annotation_json) as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for file_key, anns in annotations.items():\n",
    "    pc_filename = data_dir + file_key\n",
    "    points = np.asarray(o3d.io.read_point_cloud(pc_filename).points)\n",
    "    identifier = file_key.split('/')[-1].split('.ply')[0]\n",
    "    dataset[identifier] = {'points': points, 'annotations': np.array(anns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0eb95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_dataset = {}\n",
    "for file in Path(data_dir).joinpath('point_clouds_OO/').glob('*.ply'):\n",
    "    points = np.asarray(o3d.io.read_point_cloud(file.absolute()).points)\n",
    "    identifier = file.name.split('.ply')[0]\n",
    "    unlabelled_dataset[identifier] = {'points': points, 'annotations': np.full(len(points), -1, dtype=int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a452693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph, SAGEConv, PointNetConv\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.data import InMemoryDataset, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import math, random\n",
    "from torch.utils.data import Dataset as _TorchDataset\n",
    "\n",
    "def build_edge_labelled_knn_graph(points, point_labels, k):\n",
    "    \"\"\"\n",
    "    points: (N, d) float32 array/tensor with XYZ (or 2D) coords\n",
    "    point_labels: (N,) int/bool per-node annotations\n",
    "        Example rule below sets edge_label=1 if endpoints share the same node label.\n",
    "        Swap the rule to match your own definition.\n",
    "\n",
    "    Returns a PyG Data with:\n",
    "      - pos, x (=pos as default), edge_index\n",
    "      - edge_label_index (== edge_index)\n",
    "      - edge_label (E,)\n",
    "      - train/val/test masks over edges\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(points): points = torch.tensor(points, dtype=torch.float32)\n",
    "    if not torch.is_tensor(point_labels): point_labels = torch.tensor(point_labels)\n",
    "\n",
    "    pos = points\n",
    "\n",
    "    # kNN graph\n",
    "    edge_index = knn_graph(x=pos, k=k, loop=False)\n",
    "    edge_index = to_undirected(edge_index, num_nodes=pos.size(0))\n",
    "    src, dst = edge_index\n",
    "    edge_label = (point_labels[src] == point_labels[dst]).to(torch.long)\n",
    "\n",
    "    data = Data(\n",
    "        pos=pos, edge_index=edge_index,\n",
    "        edge_label=edge_label)\n",
    "    return data\n",
    "class RandomRotation:\n",
    "    \"\"\"Randomly rotate 3D points about a random axis or fixed axis.\"\"\"\n",
    "    def __init__(self, angle_deg=180, axis=None, seed=None):\n",
    "        self.angle_rad = math.radians(angle_deg)\n",
    "        self.axis = None if axis is None else np.asarray(axis, dtype=float)\n",
    "        self.seed = seed\n",
    "    def __call__(self, points):\n",
    "        # Accept numpy array or torch tensor; return same type as input (torch tensor if input was torch)\n",
    "        was_torch = False\n",
    "        if 'torch' in str(type(points)):\n",
    "            was_torch = True\n",
    "            pts = points.detach().cpu().numpy()\n",
    "        else:\n",
    "            pts = np.asarray(points)\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            random.seed(self.seed)\n",
    "        angle = random.uniform(-self.angle_rad, self.angle_rad)\n",
    "        if self.axis is None:\n",
    "            axis = np.random.normal(size=3)\n",
    "        else:\n",
    "            axis = np.array(self.axis, dtype=float)\n",
    "        axis = axis / (np.linalg.norm(axis) + 1e-12)\n",
    "        ux, uy, uz = axis\n",
    "        c = math.cos(angle)\n",
    "        s = math.sin(angle)\n",
    "        R = np.array([\n",
    "            [c + ux*ux*(1-c), ux*uy*(1-c) - uz*s, ux*uz*(1-c) + uy*s],\n",
    "            [uy*ux*(1-c) + uz*s, c + uy*uy*(1-c), uy*uz*(1-c) - ux*s],\n",
    "            [uz*ux*(1-c) - uy*s, uz*uy*(1-c) + ux*s, c + uz*uz*(1-c)],\n",
    "        ])\n",
    "        rotated = pts.dot(R.T)\n",
    "        if was_torch:\n",
    "            return torch.tensor(rotated, dtype=torch.float32)\n",
    "        return rotated\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "class PointNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        n_dim = 3\n",
    "        hidd_dim = 16\n",
    "\n",
    "        self.conv1 = PointNetConv(nn.Linear(2*n_dim, hidd_dim))\n",
    "        self.conv2 = PointNetConv(nn.Linear(n_dim + hidd_dim, 2*hidd_dim))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(6*hidd_dim, 2*hidd_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*hidd_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        pos, edge_index, batch = data.pos, data.edge_index, data.batch\n",
    "        h = self.conv1(x=pos, pos=pos, edge_index=edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(x=h, pos=pos, edge_index=edge_index)\n",
    "        h = h.relu()\n",
    "        src, dst = data.edge_index\n",
    "        h_i, h_j = h[src], h[dst]\n",
    "        h = torch.cat([h_i, h_j, (h_i - h_j).abs()], dim=1)\n",
    "\n",
    "        return self.classifier(h).squeeze(-1)\n",
    "\n",
    "class PCGraphDataset(_TorchDataset):\n",
    "    \"\"\"Lightweight dataset that builds kNN graph Data objects on-the-fly.\"\"\"\n",
    "    def __init__(self, data_dict, k=6, transform=None):\n",
    "        self.keys = list(data_dict.keys())\n",
    "        self.data_dict = data_dict\n",
    "        self.k = k\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        pts = self.data_dict[key]['points']\n",
    "        labs = self.data_dict[key]['annotations']\n",
    "        # center & scale\n",
    "        centered = pts - pts.mean(axis=0)\n",
    "        centered = centered / (centered.std(axis=0) + 1e-12)\n",
    "        if self.transform is not None:\n",
    "            centered = self.transform(centered)\n",
    "        return build_edge_labelled_knn_graph(centered, labs, k=self.k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b492492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (concise)\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "\n",
    "k_for_nn = 6\n",
    "transform = RandomRotation(angle_deg=180, axis=None)\n",
    "pcg_dataset = PCGraphDataset(dataset, k=k_for_nn, transform=transform)\n",
    "data_ldr = PyGDataLoader(pcg_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Note: build_edge_labelled_knn_graph creates edge_attr of size 4 (vec3 + length1)\n",
    "model = model = PointNet().to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# Compute class imbalance across the (possibly small) dataset and set pos_weight for BCEWithLogitsLoss\n",
    "try:\n",
    "    total_pos = 0\n",
    "    total_edges = 0\n",
    "    # iterate pcg_dataset (builds Data objects on-the-fly) to count positives/negatives\n",
    "    for i in range(len(pcg_dataset)):\n",
    "        d = pcg_dataset[i]\n",
    "        el = d.edge_label\n",
    "        total_pos += int(el.sum().item())\n",
    "        total_edges += int(el.numel())\n",
    "    total_neg = total_edges - total_pos\n",
    "    if total_pos == 0:\n",
    "        pos_weight = 1.0\n",
    "    else:\n",
    "        pos_weight = float(total_neg) / float(total_pos)\n",
    "    print(f'edge pos/neg = {total_pos}/{total_neg}  pos_weight={pos_weight:.4f}')\n",
    "    pos_w_tensor = torch.tensor(pos_weight, dtype=torch.float32, device=device)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_w_tensor)\n",
    "except Exception as e:\n",
    "    print('Could not compute class weights, falling back to unweighted loss:', e)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_epoch(loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_e = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        logits = model(batch)\n",
    "        labels = batch.edge_label.float().to(device)\n",
    "        loss = criterion(logits, labels)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * labels.numel()\n",
    "        total_e += labels.numel()\n",
    "    return total_loss / max(1, total_e)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            probs = torch.sigmoid(model(batch))\n",
    "            preds = (probs > 0.5).long().cpu().numpy()\n",
    "            labels = batch.edge_label.long().cpu().numpy()\n",
    "            y_pred.append(preds)\n",
    "            y_true.append(labels)\n",
    "    if len(y_true) == 0:\n",
    "        return dict(acc=0.0, prec=0.0, rec=0.0, f1=0.0)\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    fpr, trp, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "    auc = metrics.auc(fpr, trp)\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    prec = metrics.precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = metrics.recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = metrics.f1_score(y_true, y_pred, zero_division=0)\n",
    "    return dict(acc=acc, prec=prec, rec=rec, f1=f1, auc=auc)\n",
    "\n",
    "# Quick run: adjust epochs and batch_size as needed\n",
    "epochs = 100\n",
    "for ep in range(1, epochs+1):\n",
    "    loss = train_epoch(data_ldr)\n",
    "    stats = evaluate(data_ldr)\n",
    "    print(f'ep {ep:02d} loss={loss:.4f} acc={stats[\"acc\"]:.4f} f1={stats[\"f1\"]:.4f} auc={stats[\"auc\"]:.4f}')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and loader (batch=1 so we can map per-cloud)\n",
    "pcg_unlabel = PCGraphDataset(unlabelled_dataset, k=k_for_nn, transform=None)\n",
    "unl_ldr = PyGDataLoader(pcg_unlabel, batch_size=1, shuffle=False)\n",
    "\n",
    "# Run inference\n",
    "model.eval()\n",
    "predictions = {}\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(unl_ldr):\n",
    "        batch = batch.to(device)\n",
    "        logits = model(batch)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        # edge_label_index is (2, E)\n",
    "        edge_index = batch.edge_index.cpu().numpy()\n",
    "        src = edge_index[0].tolist()\n",
    "        dst = edge_index[1].tolist()\n",
    "        key = pcg_unlabel.keys[i]\n",
    "        predictions[key] = {'src': np.array(src), 'dst': np.array(dst), 'prob': np.array(probs)}\n",
    "        print(f'[{i}] {key}: edges={len(probs)} mean_prob={np.mean(probs):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c25839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "for key in predictions.keys():\n",
    "    points = unlabelled_dataset[key]['points']\n",
    "    src = predictions[key]['src']\n",
    "    dst = predictions[key]['dst']\n",
    "    probs = predictions[key]['prob']\n",
    "    pred = (probs > 0.5).astype(bool)\n",
    "    graph = nx.from_edgelist(np.vstack([src, dst]).T)\n",
    "    graph.remove_edges_from([e for i,e in enumerate(graph.edges) if not pred[i]])\n",
    "    components = list(nx.connected_components(graph))\n",
    "    labels = np.concatenate([ [c_idx]*len(components[c_idx]) for c_idx in range(len(components)) ])\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(points[:, 2], points[:, 1], points[:,0], c=labels, cmap='tab10', s=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a6327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
