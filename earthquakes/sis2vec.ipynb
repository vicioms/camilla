{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "da339fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteadDataset(Dataset):\n",
    "\n",
    "    def __init__(self, chunk_files, channel_first):\n",
    "        self.files = []\n",
    "        self.event_lists = []\n",
    "        self.stopping_indices = None\n",
    "        for chunk in chunk_files:\n",
    "            file = h5py.File(chunk, 'r')\n",
    "            metadata = pd.read_csv(chunk.replace('hdf5', 'csv'))\n",
    "            ev_list = metadata['trace_name'].astype('str').to_list()\n",
    "            self.files.append(file)\n",
    "            self.event_lists.append(ev_list)\n",
    "            if self.stopping_indices:\n",
    "                self.stopping_indices.append(self.stopping_indices[-1] + len(ev_list))\n",
    "            else:\n",
    "                self.stopping_indices = [len(ev_list)]\n",
    "        self.stopping_indices = np.array(self.stopping_indices)\n",
    "        self.channel_first = channel_first\n",
    "    def __len__(self):\n",
    "        return sum([len(ev_list) for ev_list in self.event_lists])\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # find which chunk\n",
    "        chunk_idx = 0\n",
    "        while idx >= self.stopping_indices[chunk_idx]:\n",
    "            chunk_idx += 1\n",
    "        relative_idx = idx - self.stopping_indices[chunk_idx - 1] if chunk_idx > 0 else idx\n",
    "        event_name = self.event_lists[chunk_idx][relative_idx]\n",
    "        file = self.files[chunk_idx].get('data/' + event_name)\n",
    "        trace = np.array(file)\n",
    "        p_arrival = file.attrs['p_arrival_sample']\n",
    "        s_arrival = file.attrs['s_arrival_sample']\n",
    "        coda_end = file.attrs['coda_end_sample']\n",
    "        if(p_arrival == ''):\n",
    "            p_arrival = np.nan\n",
    "        if(s_arrival == ''):\n",
    "            s_arrival = np.nan\n",
    "        if(coda_end == ''):\n",
    "            coda_end = np.nan\n",
    "        if self.channel_first:\n",
    "            trace = trace.transpose(1, 0)\n",
    "        return trace, p_arrival.item(), s_arrival.item(), coda_end.item(), event_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6222202",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time is the last dimension\n",
    "class ConvFeatureEncoder(nn.Module):\n",
    "    def __init__(self, in_ch, dim, kernel_sizes, strides, paddings):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential()\n",
    "        for i, (k, s, p) in enumerate(zip(kernel_sizes, strides, paddings)):\n",
    "            conv = nn.Conv1d(in_ch if i == 0 else dim, dim, kernel_size=k, stride=s, padding=p)\n",
    "            self.net.add_module(f\"conv_{i}\", conv)\n",
    "            self.net.add_module(f\"gelu_{i}\", nn.GELU())\n",
    "    def forward(self, x):  \n",
    "        return self.net(x)\n",
    "#time is the last dimension\n",
    "class ConvPositionalEncoding(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            channels, channels,\n",
    "            kernel_size=kernel_size,\n",
    "            groups=channels,\n",
    "            padding=kernel_size // 2,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv(x)\n",
    "# channel is the last dimension\n",
    "class ContextEncoder(nn.Module):\n",
    "    def __init__(self, dim, n_layers, n_heads, ffn_dim, dropout):\n",
    "        super().__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, \n",
    "        nhead=n_heads, \n",
    "        dim_feedforward=ffn_dim, \n",
    "        dropout=dropout, \n",
    "        activation='gelu', \n",
    "        norm_first=True, \n",
    "        batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "    def forward(self, x):\n",
    "        return self.transformer(x)\n",
    "    \n",
    "class MaskedEncoderModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_ch,\n",
    "        dim,\n",
    "        mask_prob,\n",
    "        feature_enc_kernel_sizes,\n",
    "        feature_enc_strides,\n",
    "        feature_enc_paddings,\n",
    "        context_n_layers,\n",
    "        context_n_heads,\n",
    "        context_ffn_dim,\n",
    "        context_dropout=0.1,\n",
    "        use_cpe=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.mask_prob = mask_prob\n",
    "        self.feature_encoder = ConvFeatureEncoder(\n",
    "            in_ch=in_ch,\n",
    "            dim=dim,\n",
    "            kernel_sizes=feature_enc_kernel_sizes,\n",
    "            strides=feature_enc_strides,\n",
    "            paddings=feature_enc_paddings,\n",
    "        )\n",
    "        self.use_cpe = use_cpe\n",
    "        if use_cpe:\n",
    "            self.cpe = ConvPositionalEncoding(dim, kernel_size=3)\n",
    "\n",
    "        self.context_encoder = ContextEncoder(\n",
    "            dim=dim,\n",
    "            n_layers=context_n_layers,\n",
    "            n_heads=context_n_heads,\n",
    "            ffn_dim=context_ffn_dim,\n",
    "            dropout=context_dropout\n",
    "        )\n",
    "\n",
    "        self.mask_embedding = nn.Parameter(torch.zeros(dim))\n",
    "        nn.init.normal_(self.mask_embedding, mean=0.0, std=0.02)\n",
    "\n",
    "        self.pred_head = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def random_mask(x, mask_p):\n",
    "        B, T, D = x.shape\n",
    "        mask = torch.zeros(B, T, dtype=torch.bool, device=x.device)\n",
    "        for b in range(B):\n",
    "            where_to_mask = torch.bernoulli(torch.ones(T)*mask_p)\n",
    "            if(where_to_mask.sum() == 0):\n",
    "                mask[b, torch.rand(0,T)] = True\n",
    "            else:\n",
    "                mask[b] = where_to_mask == 1\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, x, run_with_mask):\n",
    "        # 1) Conv feature encoder: (B, in_ch, T_raw) -> (B, dim, T_enc)\n",
    "        feats = self.feature_encoder(x)              # encoded targets\n",
    "\n",
    "        # 2) Optional convolutional positional encoding\n",
    "        if self.use_cpe:\n",
    "            feats = self.cpe(feats)                 # (B, dim, T_enc)\n",
    "\n",
    "\n",
    "        # 3) Prepare for transformer: (B, dim, T_enc) -> (B, T_enc, dim)\n",
    "        feats_t = feats.transpose(1, 2)             # original encoded features (targets)\n",
    "\n",
    "        if(run_with_mask):\n",
    "            # 4) Create masked input sequence\n",
    "            #masked_input = feats_t.clone()\n",
    "            #mask_bool = torch.zeros_like(feats_t[:, :, 0], dtype=torch.bool)  # (B, T_enc)\n",
    "            #mask_bool[torch.arange(0, feats_t.size(0)), torch.randint(0, feats_t.size(1), (feats_t.size(0),))] = True  # randomly mask 1 time step per sample\n",
    "            mask_bool = MaskedEncoderModel.random_mask(feats_t, self.mask_prob)\n",
    "            masked_input = feats_t.clone()\n",
    "            masked_input[mask_bool] = self.mask_embedding  # apply mask\n",
    "            ctx = self.context_encoder(masked_input)  # (B, T_enc, dim)\n",
    "            preds = self.pred_head(ctx)  # (B, T_enc, dim)\n",
    "            return preds, ctx, mask_bool\n",
    "        else:\n",
    "            ctx = self.context_encoder(feats_t)  # (B, T_enc, dim)\n",
    "            return ctx\n",
    "\n",
    "class LatentDirichletRegression(nn.Module):\n",
    "    def __init__(self,  input_dim, output_dim, kernel_sizes, channel_sizes, strides, paddings):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential()\n",
    "        for i, (k, s, p) in enumerate(zip(kernel_sizes, strides, paddings)):\n",
    "            conv = nn.Conv1d(\n",
    "                in_channels=input_dim if i == 0 else channel_sizes[i-1],\n",
    "                out_channels=channel_sizes[i],\n",
    "                kernel_size=k,\n",
    "                stride=s,\n",
    "                padding=p,\n",
    "            )\n",
    "            self.net.add_module(f\"conv_{i}\", conv)\n",
    "            self.net.add_module(f\"norm_{i}\", nn.GroupNorm(num_groups=channel_sizes[i], num_channels=channel_sizes[i]))\n",
    "            self.net.add_module(f\"gelu_{i}\", nn.GELU())\n",
    "\n",
    "        self.output_conv = nn.Sequential(nn.Conv1d(\n",
    "            in_channels=channel_sizes[-1],\n",
    "            out_channels=channel_sizes[-1],\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "        ),\n",
    "            nn.GELU())\n",
    "\n",
    "        self.output_alphas = nn.Linear(channel_sizes[-1], output_dim)\n",
    "        self.output_alpha0 = nn.Linear(channel_sizes[-1], 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.output_conv(x)\n",
    "        x = x.mean(dim=2)  # global average pooling over time dimension\n",
    "        alpha_scores = self.output_alphas(x)\n",
    "        alpha0 = F.softplus(self.output_alpha0(x))\n",
    "        return F.softmax(alpha_scores, dim=-1) * alpha0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ee551",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'STEAD/'\n",
    "train_chunks = [ root + f'chunk{chunk}/chunk{chunk}.hdf5'  for chunk in range(2, 4) ]\n",
    "val_chunks = [ root + f'chunk{chunk}/chunk{chunk}.hdf5'  for chunk in range(4, 5) ]\n",
    "train_dataset = SteadDataset(train_chunks , channel_first=True)\n",
    "val_dataset = SteadDataset(val_chunks , channel_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "feature_enc_kernel_sizes=[10,8,4]\n",
    "feature_enc_strides=[5,4,2]\n",
    "feature_enc_paddings=[5,4,2]\n",
    "p_mask = 0.15\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = MaskedEncoderModel(\n",
    "    in_ch=input_dim,\n",
    "    dim=256,\n",
    "    mask_prob=p_mask,\n",
    "    feature_enc_kernel_sizes=feature_enc_kernel_sizes,\n",
    "    feature_enc_strides=feature_enc_strides,\n",
    "    feature_enc_paddings=feature_enc_paddings,\n",
    "    context_n_layers=6,\n",
    "    context_n_heads=4,\n",
    "    context_ffn_dim=1024,\n",
    "    context_dropout=0.1,\n",
    "    use_cpe=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2859f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('STEAD/maskedencoder_epoch10.pth', map_location=device ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0) # must be 0 for hdf5\n",
    "steps_per_epoch = len(train_loader)\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "learning_rate = 3e-4\n",
    "warmup_steps = int(0.1 * num_epochs * steps_per_epoch)\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "scheduler = SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[\n",
    "        LinearLR(optimizer, start_factor=1e-3, total_iters=warmup_steps),\n",
    "        CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=num_epochs * steps_per_epoch - warmup_steps,\n",
    "            eta_min=1e-6\n",
    "        ),\n",
    "    ],\n",
    "    milestones=[warmup_steps]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14863632",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_var = 1e-3\n",
    "def vicreg_reg(z, mask, eps=1e-4, gamma=1.0):\n",
    "    # z: [B,T,C], mask: [B,T] True=masked\n",
    "    u = z[~mask]                           # [N,C]\n",
    "    if u.shape[0] < 2:\n",
    "        return z.sum() * 0.0\n",
    "\n",
    "    u = u - u.mean(dim=0, keepdim=True)\n",
    "\n",
    "    std = torch.sqrt(u.var(dim=0, unbiased=False) + eps)\n",
    "    var_loss = 0.5*torch.mean((std-gamma)**2)\n",
    "\n",
    "    # covariance term (decorrelate dims)\n",
    "    N, C = u.shape\n",
    "    cov = (u.T @ u) / (N - 1)              # [C,C]\n",
    "    offdiag = cov - torch.diag(torch.diag(cov))\n",
    "    cov_loss = (offdiag**2).mean()\n",
    "\n",
    "    return var_loss + 0.01 * cov_loss, std      # 0.01 is a decent start\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (traces, p_arrivals, s_arrivals, coda_ends, event_names) in enumerate(train_loader):\n",
    "        traces_mean = traces.mean(dim=2, keepdim=True)\n",
    "        traces_std = traces.std(dim=2, keepdim=True) + 1e-9\n",
    "        normalized_traces = (traces - traces_mean) / traces_std  # normalize input traces\n",
    "        optimizer.zero_grad()\n",
    "        ctx_preds, ctx, mask_bool = model(normalized_traces.to(device), run_with_mask=True)\n",
    "        masked_preds = ctx_preds[mask_bool]\n",
    "        masked_targets = ctx.detach()[mask_bool]\n",
    "        loss = F.mse_loss(masked_preds, masked_targets) \n",
    "        reg_loss, unmasked_ctx_std = vicreg_reg(ctx, mask_bool)\n",
    "        loss += lambda_var * reg_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if(i % 250 == 0):\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.1e}\")\n",
    "            with torch.no_grad():\n",
    "                print(unmasked_ctx_std.cpu().mean().item())\n",
    "\n",
    "    torch.save(model.state_dict(), f'STEAD/maskedencoder_epoch{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cd50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=1000, shuffle=False, num_workers=0) # must be 0 for hdf5\n",
    "with torch.no_grad():\n",
    "    for i, (traces, p_arrivals, s_arrivals, coda_ends, event_names) in enumerate(val_loader):\n",
    "        traces_mean = traces.mean(dim=2, keepdim=True)\n",
    "        traces_std = traces.std(dim=2, keepdim=True) + 1e-9\n",
    "        normalized_traces = (traces - traces_mean) / traces_std\n",
    "        ctx = model(normalized_traces.to(device), run_with_mask=False)\n",
    "        print(ctx)\n",
    "        print(ctx.var(dim=(0,1)).mean())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46efabc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ctx = model(normalized_traces.to(device), run_with_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(ctx.size(0)):\n",
    "    plt.plot(ctx[idx].cpu().numpy().mean(axis=0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efdd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "interval_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0) # must be 0 for hdf5\n",
    "interval_model = LatentDirichletRegression(\n",
    "    input_dim=256,\n",
    "    output_dim=4,\n",
    "    kernel_sizes=[3,3,3],\n",
    "    channel_sizes=[128,64,32],\n",
    "    strides=[2,2,2],\n",
    "    paddings=[1,1,1],).to(device)\n",
    "optimizer_interval = optim.Adam(interval_model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "steps_per_epoch = len(interval_dataloader)\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer_interval,\n",
    "    T_0=2 * steps_per_epoch,\n",
    "    T_mult=2,\n",
    "    eta_min=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_model.load_state_dict(torch.load('STEAD/latdirichlet_epoch10.pth', map_location=device ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e83103",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (traces, p_arrivals, s_arrivals, coda_ends, event_names) in enumerate(interval_dataloader):\n",
    "        traces_mean = traces.mean(dim=2, keepdim=True)\n",
    "        traces_std = traces.std(dim=2, keepdim=True) + 1e-9\n",
    "        normalized_traces = (traces - traces_mean) / traces_std  # normalize input traces\n",
    "        num_timesteps = traces.size(-1)\n",
    "        with torch.no_grad():\n",
    "            ctx = model(normalized_traces.to(device), run_with_mask=False)  # (B, T_enc, dim)\n",
    "            ctx_t = ctx.transpose(1, 2)  # (B, dim, T_enc)\n",
    "        optimizer_interval.zero_grad()\n",
    "        alphas = interval_model(ctx_t)  # (B, T_out)\n",
    "        dist = torch.distributions.Dirichlet(alphas + 1e-9)\n",
    "        s1 = p_arrivals/num_timesteps\n",
    "        s2 = s_arrivals/num_timesteps - s1\n",
    "        s3 = coda_ends/num_timesteps - s1 - s2\n",
    "        s4 = 1.0 - (s1 + s2 + s3)\n",
    "        target = torch.stack([s1, s2, s3, s4], dim=-1)\n",
    "        loss = -dist.log_prob(target.to(device)).mean()\n",
    "        loss.backward()\n",
    "        optimizer_interval.step()\n",
    "        scheduler.step()\n",
    "        if(i % 100 == 0):\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(interval_dataloader)}], Loss: {loss.item():.1e}\")\n",
    "    torch.save(interval_model.state_dict(), f'STEAD/latdirichlet_epoch{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b948c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    trues = []\n",
    "    preds = []\n",
    "    pred_alphas = []\n",
    "    ntraces = []\n",
    "    for i, (traces, p_arrivals, s_arrivals, coda_ends, event_names) in enumerate(interval_dataloader):\n",
    "        traces_mean = traces.mean(dim=2, keepdim=True)\n",
    "        traces_std = traces.std(dim=2, keepdim=True) + 1e-9\n",
    "        normalized_traces = (traces - traces_mean) / traces_std  # normalize input traces\n",
    "        num_timesteps = traces.size(-1)\n",
    "        ctx = model(normalized_traces.to(device), run_with_mask=False)  # (B, T_enc, dim)\n",
    "        ctx_t = ctx.transpose(1, 2)  # (B, dim, T_enc)\n",
    "        alphas = interval_model(ctx_t)  # (B, T_out)\n",
    "        dist = torch.distributions.Dirichlet(alphas + 1e-9)\n",
    "        s1 = p_arrivals/num_timesteps\n",
    "        s2 = s_arrivals/num_timesteps - s1\n",
    "        s3 = coda_ends/num_timesteps - s1 - s2\n",
    "        s4 = 1.0 - (s1 + s2 + s3)\n",
    "        target = torch.stack([s1, s2, s3, s4], dim=-1)\n",
    "        trues.append(target.cpu().numpy())\n",
    "        preds.append(dist.mean.cpu().numpy())\n",
    "        ntraces.append(normalized_traces)\n",
    "        pred_alphas.append(alphas.cpu().numpy())\n",
    "        if(i>=5):\n",
    "            break\n",
    "    trues = np.concatenate(trues, axis=0)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    ntraces = np.concatenate(ntraces, axis=0)\n",
    "    pred_alphas = np.concatenate(pred_alphas, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "for i in range(trues.shape[0]):\n",
    "    #print(stats.linregress(trues[:, i], preds[:, i]))\n",
    "    true_times = np.cumsum(trues[i])\n",
    "    pred_times = np.cumsum(preds[i])\n",
    "    distr = torch.distributions.Dirichlet(torch.from_numpy(pred_alphas[i]))\n",
    "    pred_samples = np.cumsum(distr.sample((10000,)).numpy(), axis=-1)\n",
    "\n",
    "    plt.plot(np.linspace(0,1, ntraces.shape[-1]), ntraces[i,0,:], color='gray')\n",
    "    y_min, y_max = plt.gca().get_ylim()\n",
    "    plt.vlines(true_times[:-1], y_min, y_max, color='red')\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.hist(pred_samples[:,0], bins=100, density=True, alpha=0.5)\n",
    "    ax2.hist(pred_samples[:,1], bins=100, density=True, alpha=0.5)\n",
    "    ax2.hist(pred_samples[:,2], bins=100, density=True, alpha=0.5)\n",
    "    plt.show()\n",
    "    if(i>=20):\n",
    "        break\n",
    "    #plt.vlines(pred_times[:-1], y_min, y_max, color='red')\n",
    "    #plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "organoids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
