{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da339fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'STEAD/'\n",
    "num_chunks = 2\n",
    "chunks = [ root + f'chunk{chunk}/chunk{chunk}.hdf5'  for chunk in range(1, 1+num_chunks) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class SteadDataset(Dataset):\n",
    "\n",
    "    def __init__(self, chunk_files, channel_first):\n",
    "        self.files = []\n",
    "        self.event_lists = []\n",
    "        self.stopping_indices = None\n",
    "        for chunk in chunk_files:\n",
    "            file = h5py.File(chunk, 'r')\n",
    "            metadata = pd.read_csv(chunk.replace('hdf5', 'csv'))\n",
    "            ev_list = metadata['trace_name'].astype('str').to_list()\n",
    "            self.files.append(file)\n",
    "            self.event_lists.append(ev_list)\n",
    "            if self.stopping_indices:\n",
    "                self.stopping_indices.append(self.stopping_indices[-1] + len(ev_list))\n",
    "            else:\n",
    "                self.stopping_indices = [len(ev_list)]\n",
    "        self.stopping_indices = np.array(self.stopping_indices)\n",
    "        self.channel_first = channel_first\n",
    "    def __len__(self):\n",
    "        return sum([len(ev_list) for ev_list in self.event_lists])\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # find which chunk\n",
    "        chunk_idx = 0\n",
    "        while idx >= self.stopping_indices[chunk_idx]:\n",
    "            chunk_idx += 1\n",
    "        relative_idx = idx - self.stopping_indices[chunk_idx - 1] if chunk_idx > 0 else idx\n",
    "        event_name = self.event_lists[chunk_idx][relative_idx]\n",
    "        file = self.files[chunk_idx].get('data/' + event_name)\n",
    "        trace = np.array(file)\n",
    "        p_arrival = file.attrs['p_arrival_sample']\n",
    "        s_arrival = file.attrs['s_arrival_sample']\n",
    "        coda_end = file.attrs['coda_end_sample']\n",
    "        if(p_arrival == ''):\n",
    "            p_arrival = np.nan\n",
    "        if(s_arrival == ''):\n",
    "            s_arrival = np.nan\n",
    "        if(coda_end == ''):\n",
    "            coda_end = np.nan\n",
    "        if self.channel_first:\n",
    "            trace = trace.transpose(1, 0)\n",
    "        return trace, p_arrival.item(), s_arrival.item(), coda_end.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#time is the last dimension\n",
    "class ConvFeatureEncoder(nn.Module):\n",
    "    def __init__(self, in_ch, dim, kernel_sizes, strides, paddings):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential()\n",
    "        for i, (k, s, p) in enumerate(zip(kernel_sizes, strides, paddings)):\n",
    "            conv = nn.Conv1d(in_ch if i == 0 else dim, dim, kernel_size=k, stride=s, padding=p)\n",
    "            self.net.add_module(f\"conv_{i}\", conv)\n",
    "            self.net.add_module(f\"gelu_{i}\", nn.GELU())\n",
    "    def forward(self, x):  \n",
    "        return self.net(x)\n",
    "\n",
    "#time is the last dimension\n",
    "class ConvPositionalEncoding(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            channels, channels,\n",
    "            kernel_size=kernel_size,\n",
    "            groups=channels,\n",
    "            padding=kernel_size // 2,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv(x)\n",
    "# channel is the last dimension\n",
    "class ContextEncoder(nn.Module):\n",
    "    def __init__(self, dim, n_layers, n_heads, ffn_dim, dropout):\n",
    "        super().__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=n_heads, dim_feedforward=ffn_dim, dropout=dropout, activation='gelu', batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "    def forward(self, x):\n",
    "        out = self.transformer(x)\n",
    "        return out\n",
    "    \n",
    "class MaskedEncoderModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_ch,\n",
    "        dim,\n",
    "        feature_enc_kernel_sizes,\n",
    "        feature_enc_strides,\n",
    "        feature_enc_paddings,\n",
    "        context_n_layers,\n",
    "        context_n_heads,\n",
    "        context_ffn_dim,\n",
    "        context_dropout=0.1,\n",
    "        use_cpe=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.feature_encoder = ConvFeatureEncoder(\n",
    "            in_ch=in_ch,\n",
    "            dim=dim,\n",
    "            kernel_sizes=feature_enc_kernel_sizes,\n",
    "            strides=feature_enc_strides,\n",
    "            paddings=feature_enc_paddings,\n",
    "        )\n",
    "        self.use_cpe = use_cpe\n",
    "        if use_cpe:\n",
    "            self.cpe = ConvPositionalEncoding(dim, kernel_size=3)\n",
    "\n",
    "        self.context_encoder = ContextEncoder(\n",
    "            dim=dim,\n",
    "            n_layers=context_n_layers,\n",
    "            n_heads=context_n_heads,\n",
    "            ffn_dim=context_ffn_dim,\n",
    "            dropout=context_dropout\n",
    "        )\n",
    "\n",
    "        self.mask_embedding = nn.Parameter(torch.zeros(dim))\n",
    "        nn.init.normal_(self.mask_embedding, mean=0.0, std=0.02)\n",
    "\n",
    "        self.pred_head = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, run_with_mask):\n",
    "        # 1) Conv feature encoder: (B, in_ch, T_raw) -> (B, dim, T_enc)\n",
    "        feats = self.feature_encoder(x)              # encoded targets\n",
    "\n",
    "        # 2) Optional convolutional positional encoding\n",
    "        if self.use_cpe:\n",
    "            feats = self.cpe(feats)                 # (B, dim, T_enc)\n",
    "\n",
    "\n",
    "        # 3) Prepare for transformer: (B, dim, T_enc) -> (B, T_enc, dim)\n",
    "        feats_t = feats.transpose(1, 2)             # original encoded features (targets)\n",
    "\n",
    "        if(run_with_mask):\n",
    "            # 4) Create masked input sequence\n",
    "            masked_input = feats_t.clone()\n",
    "            mask_bool = torch.zeros_like(feats_t[:, :, 0], dtype=torch.bool)  # (B, T_enc)\n",
    "            mask_bool[torch.arange(0, feats_t.size(0)), torch.randint(0, feats_t.size(1), (feats_t.size(0),))] = True  # randomly mask 1 time step per sample\n",
    "            masked_input[mask_bool] = self.mask_embedding  # apply mask\n",
    "            ctx = self.context_encoder(masked_input)  # (B, T_enc, dim)\n",
    "            preds = self.pred_head(ctx)  # (B, T_enc, dim)\n",
    "            return preds, feats_t, mask_bool\n",
    "        else:\n",
    "            ctx = self.context_encoder(feats_t)  # (B, T_enc, dim)\n",
    "            return ctx\n",
    "        \n",
    "\n",
    "class EncodedSegmentation(nn.Module):\n",
    "    def __init__(self, input_dim, input_timesteps,output_timesteps, kernel_sizes, strides, paddings):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.input_timesteps = input_timesteps\n",
    "        self.output_timesteps = output_timesteps\n",
    "        self.up_sampler = nn.Sequential()\n",
    "        current_length = input_timesteps\n",
    "        for i, (k, s, p) in enumerate(zip(kernel_sizes, strides, paddings)):\n",
    "            out_p = s -1\n",
    "            #out_p = 0\n",
    "            conv_transpose = nn.ConvTranspose1d(\n",
    "                in_channels=input_dim,\n",
    "                out_channels=input_dim,\n",
    "                kernel_size=k,\n",
    "                stride=s,\n",
    "                padding=p,\n",
    "                output_padding=out_p,\n",
    "            )\n",
    "            current_length = (current_length - 1) * s - 2 * p + (k-1) + out_p + 1\n",
    "            self.up_sampler.add_module(f\"conv_transpose_{i}\", conv_transpose)\n",
    "            self.up_sampler.add_module(f\"gelu_{i}\", nn.GELU())\n",
    "        if(current_length > output_timesteps):\n",
    "            self.up_sampler.add_module(\"crop_conv\",nn.Conv1d(\n",
    "                in_channels=input_dim,\n",
    "                out_channels=input_dim,\n",
    "                kernel_size=2,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                dilation=current_length - output_timesteps,))\n",
    "            self.up_sampler.add_module(\"crop_gelu\", nn.GELU())\n",
    "        elif(current_length < output_timesteps):\n",
    "            self.up_sampler.add_module(\"pad_layer\", nn.ConstantPad1d((0, output_timesteps - current_length), 0.0))\n",
    "    \n",
    "        self.segmentation_head = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=input_dim,\n",
    "                out_channels=1,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ))\n",
    "    def forward(self, x):\n",
    "        upsampled_x =  self.up_sampler(x)\n",
    "        return self.segmentation_head(upsampled_x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ee551",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SteadDataset(chunks[1:] , channel_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "num_epochs = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "p_mask = 0.01\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0) # must be 0 for hdf5\n",
    "\n",
    "feature_enc_kernel_sizes=[10,8,4]\n",
    "feature_enc_strides=[5,4,2]\n",
    "feature_enc_paddings=[5,4,2]\n",
    "model = MaskedEncoderModel(\n",
    "    in_ch=input_dim,\n",
    "    dim=256,\n",
    "    feature_enc_kernel_sizes=feature_enc_kernel_sizes,\n",
    "    feature_enc_strides=feature_enc_strides,\n",
    "    feature_enc_paddings=feature_enc_paddings,\n",
    "    context_n_layers=4,\n",
    "    context_n_heads=8,\n",
    "    context_ffn_dim=512,\n",
    "    context_dropout=0.1,\n",
    "    use_cpe=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14863632",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (traces, p_arrivals, s_arrivals, coda_ends) in enumerate(dataloader):\n",
    "        traces_mean = traces.mean(dim=2, keepdim=True)\n",
    "        traces_std = traces.std(dim=2, keepdim=True) + 1e-9\n",
    "        normalized_traces = (traces - traces_mean) / traces_std  # normalize input traces\n",
    "        optimizer.zero_grad()\n",
    "        preds, feats_t, mask_bool = model(normalized_traces, run_with_mask=True)\n",
    "        masked_preds = preds[mask_bool]\n",
    "        masked_targets = feats_t[mask_bool]\n",
    "        loss = F.mse_loss(masked_preds, masked_targets)   \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efdd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0) # must be 0 for hdf5\n",
    "segmentation_model = EncodedSegmentation(input_dim=256, input_timesteps=151, output_timesteps=6000, \n",
    "                                 kernel_sizes=np.flip(feature_enc_kernel_sizes),\n",
    "                                 strides=np.flip(feature_enc_strides), \n",
    "                                 paddings=np.flip(feature_enc_paddings))\n",
    "optimizer_seg = optim.Adam(segmentation_model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (traces, p_arrivals, s_arrivals, coda_ends) in enumerate(dataloader):\n",
    "        traces_mean = traces.mean(dim=2, keepdim=True)\n",
    "        traces_std = traces.std(dim=2, keepdim=True) + 1e-9\n",
    "        normalized_traces = (traces - traces_mean) / traces_std  # normalize input traces\n",
    "        with torch.no_grad():\n",
    "            encoded_feats = model(normalized_traces, run_with_mask=False)  # (B, T_enc, dim)\n",
    "            encoded_feats_t = encoded_feats.transpose(1, 2)  # (B, dim, T_enc)\n",
    "        \n",
    "        \n",
    "        optimizer_seg.zero_grad()\n",
    "        seg_outputs = segmentation_model(encoded_feats_t)  # (B, T_out)\n",
    "        initial_indices = torch.floor(p_arrivals).long()\n",
    "        final_indices = torch.ceil(s_arrivals).long()\n",
    "        positions = torch.arange(seg_outputs.size(1)).unsqueeze(0).expand(seg_outputs.size(0), -1)  # [0..T-1]\n",
    "        labels = (positions >= initial_indices.unsqueeze(1)) & (positions < final_indices.unsqueeze(1))\n",
    "        loss = criterion(seg_outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer_seg.step()\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ec6eb",
   "metadata": {},
   "source": [
    "# OBSPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"IRIS\")\n",
    "inventory = client.get_stations(\n",
    "    minlongitude=6.0,\n",
    "    maxlongitude=19.0,\n",
    "    minlatitude=35.0,\n",
    "    maxlatitude=47.0,    \n",
    "    channel=\"BHZ\",\n",
    "    level=\"response\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "def extract_traces(inventory, t0, duration_seconds, sampling_rate):\n",
    "    t1 = t0 + duration_seconds\n",
    "    traces = []\n",
    "    for net in inventory:\n",
    "        for sta in net:\n",
    "\n",
    "            # --- controllo periodo operativo (robusto) ---\n",
    "            if sta.start_date and sta.start_date > t0:\n",
    "                continue\n",
    "            if sta.end_date and sta.end_date < t1:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # wildcard su location\n",
    "                st = client.get_waveforms(\n",
    "                    net.code,\n",
    "                    sta.code,\n",
    "                    \"*\",\n",
    "                    \"BHZ\",\n",
    "                    t0,\n",
    "                    t1,\n",
    "                    attach_response=True\n",
    "                )\n",
    "\n",
    "                # se arrivano più location, scegli una (es. \"00\" se c'è)\n",
    "                if len(set(tr.stats.location for tr in st)) > 1:\n",
    "                    if \"00\" in [tr.stats.location for tr in st]:\n",
    "                        st = st.select(location=\"00\")\n",
    "                    else:\n",
    "                        st = st[:1]  # prendine una e basta\n",
    "\n",
    "                #print(f\"SUCCESS {net.code}.{sta.code}.{st[0].stats.location}.BHZ\")\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            trp = st[0].copy()\n",
    "\n",
    "            trp.detrend(\"linear\")\n",
    "            trp.taper(max_percentage=0.05, type=\"hann\")  # 5% cosine taper at both ends\n",
    "            \n",
    "            #trp.detrend(\"demean\")\n",
    "            #trp.taper(0.02)\n",
    "#\n",
    "            #trp.remove_response(\n",
    "            #    inventory=inventory,\n",
    "            #    output=\"VEL\",\n",
    "            #    pre_filt=(0.2, 0.5, 15, 20),\n",
    "            #)\n",
    "\n",
    "            #trp.filter(\"bandpass\", freqmin=0.5, freqmax=15.0, corners=4, zerophase=True)\n",
    "            f_nyq = trp.stats.sampling_rate / 2\n",
    "            freqmax = min(10, 0.9 * f_nyq)  # 90% of Nyquist\n",
    "            trp.filter(\"bandpass\", freqmin=2.0, freqmax=freqmax, corners=4, zerophase=True)\n",
    "            trp.resample(sampling_rate)\n",
    "\n",
    "\n",
    "            x = trp.data.astype(np.float32)\n",
    "            traces.append(x)\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 60*10\n",
    "sampling_rate = 50.0  # Hz\n",
    "t0 = UTCDateTime(\"2016-08-24T01:35:00\")\n",
    "t1 = t0 + duration\n",
    "traces = extract_traces(inventory, t0, duration, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61850a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_timeseries_lagged_infos(x1, x2, window_size, lag):\n",
    "    \"\"\"\n",
    "    x1, x2: 1D numpy arrays of the same length\n",
    "    window_size: size of the moving window\n",
    "    lag: lag between the two time series (in samples)\n",
    "    \"\"\"\n",
    "    n = len(x1)\n",
    "    assert len(x2) == n, \"Time series must have the same length\"\n",
    "    assert abs(lag) < n, \"Lag must be less than the length of the time series\"\n",
    "\n",
    "    infos = []\n",
    "    for start in range(0, n - window_size + 1):\n",
    "        end = start + window_size\n",
    "        segment1 = x1[start:end]\n",
    "        segment2 = x2[start + lag:end + lag]\n",
    "        if(len(segment2) != window_size):\n",
    "            continue\n",
    "\n",
    "\n",
    "        infos.append(np.cov(segment1, segment2))\n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = int(10.0 * sampling_rate)\n",
    "lag = int(3.0 * sampling_rate)\n",
    "results= []\n",
    "variance_of_mutuals = []\n",
    "mutuals = []\n",
    "for info in two_timeseries_lagged_infos(traces[0], traces[3], window_size, lag):\n",
    "    variance_of_mutuals.append(info[0,1]**2 / (info[0,0]*info[1,1]))\n",
    "    mutuals.append(-0.5*np.log(1-variance_of_mutuals[-1]))\n",
    "    vals = np.linalg.eigvalsh(info)\n",
    "    results.append(vals)\n",
    "results = np.array(results)\n",
    "variance_of_mutuals = np.array(variance_of_mutuals)\n",
    "mutuals = np.array(mutuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0520df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "\n",
    "axs[0].plot(variance_of_mutuals/mutuals)\n",
    "axs[1].plot(traces[0], color='red', alpha=0.5)\n",
    "axs[1].plot(traces[1], color='blue', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482ee1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "organoids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
