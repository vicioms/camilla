{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ngl import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icosphere(level):\n",
    "    \"\"\"\n",
    "    Build an R-refined icosahedral mesh on the unit sphere.\n",
    "\n",
    "    level = 0 -> base icosahedron (12 vertices, 20 faces)\n",
    "    level = 1 -> 42 vertices, 80 faces\n",
    "    ...\n",
    "    level = 6 -> 40962 vertices, 81920 faces  (GraphCast-like)\n",
    "    \"\"\"\n",
    "    def _create_icosahedron():\n",
    "        \"\"\"Regular unit icosahedron (12 vertices, 20 faces) on the unit sphere.\"\"\"\n",
    "        phi = (1.0 + np.sqrt(5.0)) / 2.0\n",
    "\n",
    "        # Raw coordinates\n",
    "        verts = np.array([\n",
    "            [-1,  phi,  0],\n",
    "            [ 1,  phi,  0],\n",
    "            [-1, -phi,  0],\n",
    "            [ 1, -phi,  0],\n",
    "            [ 0, -1,  phi],\n",
    "            [ 0,  1,  phi],\n",
    "            [ 0, -1, -phi],\n",
    "            [ 0,  1, -phi],\n",
    "            [ phi,  0, -1],\n",
    "            [ phi,  0,  1],\n",
    "            [-phi,  0, -1],\n",
    "            [-phi,  0,  1],\n",
    "        ], dtype=float)\n",
    "\n",
    "        # Normalize to unit sphere\n",
    "        verts /= np.linalg.norm(verts, axis=1, keepdims=True)\n",
    "\n",
    "        # Faces (triangles) â€” standard icosahedron connectivity\n",
    "        faces = np.array([\n",
    "            [0, 11, 5],\n",
    "            [0, 5, 1],\n",
    "            [0, 1, 7],\n",
    "            [0, 7, 10],\n",
    "            [0, 10, 11],\n",
    "            [1, 5, 9],\n",
    "            [5, 11, 4],\n",
    "            [11, 10, 2],\n",
    "            [10, 7, 6],\n",
    "            [7, 1, 8],\n",
    "            [3, 9, 4],\n",
    "            [3, 4, 2],\n",
    "            [3, 2, 6],\n",
    "            [3, 6, 8],\n",
    "            [3, 8, 9],\n",
    "            [4, 9, 5],\n",
    "            [2, 4, 11],\n",
    "            [6, 2, 10],\n",
    "            [8, 6, 7],\n",
    "            [9, 8, 1],\n",
    "        ], dtype=int)\n",
    "\n",
    "        return verts, faces\n",
    "    def _subdivide_icosphere(vertices, faces):\n",
    "        \"\"\"\n",
    "        One refinement step: split each triangle into 4.\n",
    "        Vertices stay on the unit sphere.\n",
    "        \"\"\"\n",
    "        # We'll add new vertices on the fly and cache midpoints so we don't duplicate them.\n",
    "        midpoint_cache = {}\n",
    "        verts_list = vertices.tolist()\n",
    "        new_faces = []\n",
    "\n",
    "        def get_midpoint(i, j):\n",
    "            key = tuple(sorted((i, j)))\n",
    "            if key in midpoint_cache:\n",
    "                return midpoint_cache[key]\n",
    "\n",
    "            vi = np.array(verts_list[i])\n",
    "            vj = np.array(verts_list[j])\n",
    "            m = (vi + vj) * 0.5\n",
    "            m /= np.linalg.norm(m)  # project to unit sphere\n",
    "\n",
    "            verts_list.append(m.tolist())\n",
    "            idx = len(verts_list) - 1\n",
    "            midpoint_cache[key] = idx\n",
    "            return idx\n",
    "\n",
    "        for tri in faces:\n",
    "            i, j, k = tri\n",
    "            a = get_midpoint(i, j)\n",
    "            b = get_midpoint(j, k)\n",
    "            c = get_midpoint(k, i)\n",
    "\n",
    "            # 4 new triangles\n",
    "            new_faces.append([i, a, c])\n",
    "            new_faces.append([j, b, a])\n",
    "            new_faces.append([k, c, b])\n",
    "            new_faces.append([a, b, c])\n",
    "\n",
    "        new_vertices = np.array(verts_list, dtype=float)\n",
    "        new_faces = np.array(new_faces, dtype=int)\n",
    "        return new_vertices, new_faces\n",
    "    verts, faces = _create_icosahedron()\n",
    "    for _ in range(level):\n",
    "        verts, faces = _subdivide_icosphere(verts, faces)\n",
    "    return verts, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bac429",
   "metadata": {},
   "outputs": [],
   "source": [
    "icos_verts, icos_faces = icosphere(level=5)\n",
    "icos_lats = np.degrees(np.arcsin(icos_verts[:, 2]))\n",
    "icos_lons = np.degrees(np.arctan2(icos_verts[:, 1], icos_verts[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = fetch_station_24h_final()\n",
    "stations['x'] = np.cos(np.radians(stations['lat'])) * np.cos(np.radians(stations['lon']))\n",
    "stations['y'] = np.cos(np.radians(stations['lat'])) * np.sin(np.radians(stations['lon']))\n",
    "stations['z'] = np.sin(np.radians(stations['lat']))\n",
    "stations_lat_lon = stations[['lat', 'lon']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f83490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.metrics.pairwise import haversine_distances    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_balltree = BallTree(stations_lat_lon,  metric='haversine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694581c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_name in tqdm(stations['station'].values):\n",
    "    try:\n",
    "        fetch_IGS20_24h_final(station_name, \"tenv\", \"IGS20_24h_final/\", overwrite=False)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Failed to fetch data for station {station_name}: {e}\")\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a3cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for station_file in tqdm(list(pathlib.Path(\"IGS20_24h_final/\").glob(\"*.csv\"))):\n",
    "    try:\n",
    "        dataframes.append(pd.read_csv(station_file.absolute(), sep=\",\", parse_dates=['date']))\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Failed to read data for station {station_file.name}: {e}\")\n",
    "        continue\n",
    "dataframes = pd.concat(dataframes, ignore_index=True)\n",
    "dataframes['date'] = dataframes['date'].values.astype('datetime64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframes.set_index(['station', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8835b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = np.unique(dataframes['date']).astype('datetime64[D]')\n",
    "min_date = unique_dates.min()\n",
    "max_date = unique_dates.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['delta_e_m','delta_n_m','delta_v_m']\n",
    "\n",
    "df = dataframes[['station', 'date'] + cols].copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['station','date'])\n",
    "\n",
    "g = df.groupby('station', sort=False)\n",
    "\n",
    "# raw diffs\n",
    "df[cols] = g[cols].diff()\n",
    "\n",
    "# only keep diffs if previous row is exactly 1 day earlier\n",
    "dt = g['date'].diff()\n",
    "ok = dt.eq(pd.Timedelta(days=1))\n",
    "\n",
    "df.loc[~ok, cols] = np.nan   # breaks at gaps (and first row per station)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bac169",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size_num_days = 7\n",
    "window_size = np.timedelta64(window_size_num_days, 'D')\n",
    "cols = ['delta_e_m', 'delta_n_m', 'delta_v_m']\n",
    "nan_row = pd.Series({c: np.nan for c in cols})\n",
    "def displacement_extract(df):\n",
    "    start_pos = df.iloc[0][cols]\n",
    "    end_pos = df.iloc[-1][cols]\n",
    "    displacement = end_pos - start_pos\n",
    "    return displacement\n",
    "all_displacements = []\n",
    "for start_date in tqdm(np.arange(min_date, max_date, np.timedelta64(1, 'D'))):\n",
    "    subset_mask = (dataframes['date'] >= start_date) & (dataframes['date'] < start_date + window_size)\n",
    "    subset = dataframes.loc[subset_mask]\n",
    "    subset = subset.groupby('station').filter(lambda x: len(x) == window_size_num_days).reset_index(drop=True)\n",
    "    displacements = subset[['station', 'date'] + cols].groupby('station').apply(lambda df: displacement_extract(df.sort_values('date')), include_groups=False)\n",
    "    displacements['start_date'] = start_date\n",
    "    displacements['end_date'] = start_date + window_size - np.timedelta64(1, 'D')\n",
    "    all_displacements.append(displacements)\n",
    "all_displacements = pd.concat(all_displacements, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
