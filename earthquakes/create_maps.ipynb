{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e0c5e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import dateutil\n",
    "from datetime import datetime, timedelta\n",
    "from math import ceil, floor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c8f6a",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8497e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jma_monthly_fetch(verbose=False, min_year=0):\n",
    "    dataframes = {}\n",
    "    BASE = \"https://www.fnet.bosai.go.jp/event/mcata/\"\n",
    "    URL_DATA = BASE + \"data/\"\n",
    "    HEADERS = {\"User-Agent\": \"research/academic use (schimmenti@pks.mpg.de)\"}\n",
    "    html = requests.get(BASE, headers=HEADERS, timeout=30).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    years = []\n",
    "    for el in soup.find_all(\"td\"):\n",
    "        if(el.get('class') == ['cdir']):\n",
    "            year = int(el.text.strip())\n",
    "            years.append(year)\n",
    "    for year in years:\n",
    "        if(year < min_year):\n",
    "            continue\n",
    "        for month in range(1,13):\n",
    "            url = URL_DATA +  f\"{year}/{year:04d}{month:02d}_UT.txt\"\n",
    "            try:\n",
    "                df = pd.read_csv(url, comment='#', sep='\\\\s+')\n",
    "                df['Origin_Time(UT)'] = df['Origin_Time(UT)'].str.replace(\",\", \"T\")\n",
    "                df['Origin_Time(UT)'] = pd.to_datetime(df['Origin_Time(UT)'].str.replace(\"/\", \"-\"))\n",
    "                df['Strike'] = df['Strike'].str.replace(\";\", \".\")\n",
    "                df['Dip'] = df['Dip'].str.replace(\";\", \".\")\n",
    "                df['Rake'] = df['Rake'].str.replace(\";\", \".\")\n",
    "                dataframes[(year, month)] = df\n",
    "                if(verbose):\n",
    "                    print(f\"Fetched year {year} and month {month}\")\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return pd.concat(dataframes).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef63bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = jma_monthly_fetch(verbose=True, min_year=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b40ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.to_csv('japanese-cat.csv', index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c449270",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7844f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv('japanese-cat.csv', sep=' ', parse_dates=['Origin_Time(UT)']).sort_values(by='Origin_Time(UT)').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97401b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_origin = np.datetime64(datetime(1997,1,1))\n",
    "time_resolution = np.timedelta64(timedelta(days=0.1)).astype('timedelta64[s]').astype('float')\n",
    "catalog['gap'] = np.ceil((catalog['Origin_Time(UT)'] - time_origin).astype('timedelta64[s]').values.astype('float')/time_resolution).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = 18.0\n",
    "max_lat = 50.0\n",
    "min_lon = 119.0\n",
    "max_lon = 156.0\n",
    "space_resolution = 0.1\n",
    "catalog['lat_idx'] = np.floor((catalog['Latitude(deg)'] - min_lat)/space_resolution).astype('int')\n",
    "catalog['lon_idx'] = np.floor((catalog['Longitude(deg)'] - min_lon)/space_resolution).astype('int')\n",
    "spatial_shape = (ceil((max_lat-min_lat)/space_resolution), ceil((max_lon-min_lon)/space_resolution))\n",
    "counts = np.zeros(spatial_shape)\n",
    "avg_m = np.zeros(spatial_shape)\n",
    "np.add.at(counts, (catalog['lat_idx'].values,catalog['lon_idx'].values ), 1.0)\n",
    "np.add.at(avg_m, (catalog['lat_idx'].values,catalog['lon_idx'].values ), catalog['MT_Magnitude(Mw)'].values)\n",
    "avg_m = np.divide(avg_m, counts, where=counts>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed898219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "organoids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
