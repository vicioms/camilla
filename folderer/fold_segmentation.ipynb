{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f5e7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import inspect\n",
    "import tqdm\n",
    "from typing import Any, Optional, Dict, List, Tuple, Callable, Union\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sparse\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import igl\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f95eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_mesh_open3d(mesh: o3d.geometry.TriangleMesh) -> o3d.geometry.TriangleMesh:\n",
    "    ret_mesh = mesh.remove_duplicated_triangles()\n",
    "    ret_mesh = ret_mesh.remove_duplicated_vertices()\n",
    "    ret_mesh = ret_mesh.remove_degenerate_triangles()\n",
    "    ret_mesh = ret_mesh.remove_non_manifold_edges()\n",
    "    ret_mesh = ret_mesh.remove_unreferenced_vertices()\n",
    "\n",
    "    # Keep only the largest connected component\n",
    "    clusters, lengths, _ = ret_mesh.cluster_connected_triangles()\n",
    "    clusters = np.asarray(clusters)\n",
    "    lengths = np.asarray(lengths)\n",
    "    largest_cluster = np.argmax(lengths)\n",
    "    ret_mesh.remove_triangles_by_index(\n",
    "        np.where(clusters != largest_cluster)[0]\n",
    "    )\n",
    "    ret_mesh = ret_mesh.remove_unreferenced_vertices()\n",
    "\n",
    "    # Remove non-manifold vertices\n",
    "    nm_verts = ret_mesh.get_non_manifold_vertices()\n",
    "    if len(nm_verts) > 0:\n",
    "        ret_mesh.remove_vertices_by_index(nm_verts)\n",
    "\n",
    "    # Final clean-up\n",
    "    ret_mesh = ret_mesh.remove_non_manifold_edges()\n",
    "    ret_mesh = ret_mesh.remove_unreferenced_vertices()\n",
    "    return ret_mesh\n",
    "def _orient_mesh_by_centroid(vertices : np.ndarray,\n",
    "                             triangles : np.ndarray,\n",
    "                             vertex_normals : np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    flip = np.mean((vertices - vertices.mean(axis=0, keepdims=True))*vertex_normals > 0) < 0.5\n",
    "    if flip:\n",
    "        triangles = triangles[:, [2, 1, 0]]\n",
    "        if vertex_normals is not None:\n",
    "            vertex_normals = -vertex_normals\n",
    "    return triangles, vertex_normals\n",
    "def _process_mesh(\n",
    "    mesh: Optional[o3d.geometry.TriangleMesh] = None,\n",
    "    vertices: Optional[np.ndarray] = None,\n",
    "    triangles: Optional[np.ndarray] = None,\n",
    "    scale: Union[float, Tuple[float, float, float]] = 1.0,\n",
    "    invert_axis: Tuple[bool, bool, bool] = (False, False, False),\n",
    "    mesh_clean_pipeline: Callable = _clean_mesh_open3d,\n",
    "    mesh_clean_pipeline_params: Optional[Dict] = None,\n",
    "    orient_by_centroid: bool = False,\n",
    "    return_as_numpy: bool = False,\n",
    "):\n",
    "    # --- get V,F as numpy ---\n",
    "    if mesh is None:\n",
    "        if vertices is None or triangles is None:\n",
    "            raise ValueError(\"Either mesh or both vertices and triangles must be provided.\")\n",
    "        V = np.asarray(vertices, dtype=np.float64).copy()\n",
    "        F = np.asarray(triangles, dtype=np.int32).copy()\n",
    "        mesh = o3d.geometry.TriangleMesh()\n",
    "    else:\n",
    "        V = np.asarray(mesh.vertices).copy()\n",
    "        F = np.asarray(mesh.triangles).copy()\n",
    "\n",
    "    # --- preprocess in numpy ---\n",
    "    if scale != 1.0:\n",
    "        if isinstance(scale, (int, float)):\n",
    "            V *= scale\n",
    "        else:\n",
    "            V *= np.array(scale)\n",
    "\n",
    "    for axis, inv in enumerate(invert_axis):\n",
    "        if inv:\n",
    "            mn, mx = V[:, axis].min(), V[:, axis].max()\n",
    "            V[:, axis] = (mx + mn) - V[:, axis]\n",
    "\n",
    "    # odd number of reflections => flip winding\n",
    "    if sum(bool(x) for x in invert_axis) % 2 == 1:\n",
    "        F = F[:, [0, 2, 1]]\n",
    "\n",
    "    # --- write back before normals/orientation ---\n",
    "    mesh.vertices = o3d.utility.Vector3dVector(V)\n",
    "    mesh.triangles = o3d.utility.Vector3iVector(F)\n",
    "\n",
    "    # now normals correspond to the current geometry\n",
    "    mesh.compute_vertex_normals()\n",
    "    N = np.asarray(mesh.vertex_normals)\n",
    "\n",
    "    if orient_by_centroid:\n",
    "        F2, N2 = _orient_mesh_by_centroid(V, F, N)\n",
    "        F = F2\n",
    "        # write updated triangles and recompute normals (safest)\n",
    "        mesh.triangles = o3d.utility.Vector3iVector(F)\n",
    "        mesh.compute_vertex_normals()\n",
    "        N = np.asarray(mesh.vertex_normals)\n",
    "\n",
    "\n",
    "    if mesh_clean_pipeline is not None:\n",
    "        params = dict(mesh_clean_pipeline_params or {})\n",
    "        sig = inspect.signature(mesh_clean_pipeline)\n",
    "\n",
    "        has_var_kwargs = any(\n",
    "            p.kind == inspect.Parameter.VAR_KEYWORD\n",
    "            for p in sig.parameters.values()\n",
    "        )\n",
    "\n",
    "        if not has_var_kwargs:\n",
    "            # filter params\n",
    "            params = {k: v for k, v in params.items() if k in sig.parameters}\n",
    "\n",
    "        # inject core objects if accepted and not already provided\n",
    "        if 'mesh' in sig.parameters and 'mesh' not in params:\n",
    "            params['mesh'] = mesh\n",
    "        if 'vertices' in sig.parameters and 'vertices' not in params:\n",
    "            params['vertices'] = V\n",
    "        if 'triangles' in sig.parameters and 'triangles' not in params:\n",
    "            params['triangles'] = F\n",
    "\n",
    "        mesh = mesh_clean_pipeline(**params)\n",
    "\n",
    "\n",
    "    if return_as_numpy:\n",
    "        return np.asarray(mesh.vertices), np.asarray(mesh.triangles)\n",
    "    return mesh\n",
    "def _load_and_process_mesh(file_path : str | Path, scale : float = 1.0, invert_axis : Tuple[bool, bool, bool] = (False, False, False), orient_by_centroid: bool = False, return_as_numpy: bool = False) -> Union[o3d.geometry.TriangleMesh, Tuple[np.ndarray, np.ndarray]]:\n",
    "    mesh = o3d.io.read_triangle_mesh(str(file_path))\n",
    "    return _process_mesh(mesh=mesh,\n",
    "                            scale=scale,\n",
    "                            invert_axis=invert_axis,\n",
    "                            mesh_clean_pipeline=_clean_mesh_open3d,\n",
    "                            orient_by_centroid=orient_by_centroid, return_as_numpy=return_as_numpy)\n",
    "def load_and_process_meshes(mesh_info_dict : Union[Dict[Any, dict]], verbose : bool = False) -> Dict[Any, Tuple[np.ndarray, np.ndarray]]:\n",
    "    processed_meshes = {}   \n",
    "    pbar = tqdm.tqdm(mesh_info_dict.items(), disable=not verbose)\n",
    "    for name, fields in pbar:\n",
    "        pbar.set_description(f\"Processing mesh: {name}\")\n",
    "        vertices, triangles = _load_and_process_mesh(fields['path'], scale=fields.get('scale', 1.0),\n",
    "                                                      invert_axis=fields.get('invert_axis', (False, False, False)), \n",
    "                                                      orient_by_centroid=fields.get('orient_by_centroid', False), \n",
    "                                                      return_as_numpy=True)\n",
    "        processed_meshes[name] = (vertices, triangles)\n",
    "    return processed_meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bd5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldSegmentation:\n",
    "    def __init__(self, \n",
    "                 initial_params : Dict,\n",
    "                 vertices : np.ndarray, \n",
    "                 triangles : np.ndarray,\n",
    "                 exclude_boundary_loop : bool = True):\n",
    "        self.segmentation_params_types = {\n",
    "                    'min_H': float,\n",
    "                    'max_H': float,\n",
    "                    'use_pc2': bool,\n",
    "                    'pc2_quantile': float,\n",
    "                    'max_num_clusters': int,\n",
    "                    'expand_distance': float,\n",
    "                    'expand_graph_distance': int,\n",
    "                    'join_method': str,  # 'and' or 'or'\n",
    "                    }\n",
    "        self.vertices = vertices\n",
    "        self.triangles = triangles\n",
    "        self.vertex_normals = igl.per_vertex_normals(vertices, triangles)\n",
    "        principal_curvatures = igl.principal_curvature(vertices, triangles)\n",
    "        self.vertex_pc1_values, self.vertex_pc2_values = principal_curvatures[2], principal_curvatures[3]\n",
    "        #self.vertex_mean_curvature = (self.vertex_pc1_values + self.vertex_pc2_values) / 2.0\n",
    "        cotmatrix = igl.cotmatrix(vertices, triangles)\n",
    "        massmatrix = igl.massmatrix(vertices, triangles, igl.MASSMATRIX_TYPE_VORONOI)\n",
    "        laplacian = sparse.linalg.inv(massmatrix) @ cotmatrix\n",
    "        self.vertex_mean_curvature = np.sum((laplacian @ vertices)*self.vertex_normals, axis=1)\n",
    "        self.boundary_loop = igl.boundary_loop(triangles)\n",
    "        if exclude_boundary_loop:\n",
    "            self.vertex_mean_curvature[self.boundary_loop] = np.nan\n",
    "            self.vertex_pc2_values[self.boundary_loop] = np.nan\n",
    "        self.vertex_adj_list = igl.adjacency_list(triangles)\n",
    "        self.adj_graph = nx.from_dict_of_lists({i: nbrs for i, nbrs in enumerate(self.vertex_adj_list)})\n",
    "        self.params = {}\n",
    "        for param_name, param_type in self.segmentation_params_types.items():\n",
    "            if param_name in initial_params:\n",
    "                if not isinstance(initial_params[param_name], param_type):\n",
    "                    raise ValueError(f\"Parameter {param_name} must be of type {param_type}.\")\n",
    "                self.params[param_name] = initial_params[param_name]\n",
    "            else:\n",
    "                raise ValueError(f\"Missing required parameter: {param_name}\")\n",
    "        self.tree = KDTree(self.vertices)\n",
    "        self._mean_curvature_mask = None\n",
    "        self._pc2_mask = None\n",
    "        self._clusters = None\n",
    "        self._expanded_clusters = None\n",
    "\n",
    "    def update_parameter(self, param_name: str, param_value, invalidate_caches: bool = True) -> bool:\n",
    "        if param_name not in self.segmentation_params_types:\n",
    "            raise ValueError(f\"Unknown parameter: {param_name}\")\n",
    "        if not isinstance(param_value, self.segmentation_params_types[param_name]):\n",
    "            raise ValueError(f\"Parameter {param_name} must be of type {self.segmentation_params_types[param_name]}.\")\n",
    "        old_value = self.params[param_name]\n",
    "        self.params[param_name] = param_value\n",
    "        parameter_changed = old_value != param_value\n",
    "        if invalidate_caches and parameter_changed:\n",
    "            if param_name in ['min_H', 'max_H']:\n",
    "                self._mean_curvature_mask = None\n",
    "                self._clusters = None\n",
    "            if param_name in ['use_pc2', 'pc2_quantile']:\n",
    "                self._pc2_mask = None\n",
    "                self._clusters = None\n",
    "            if param_name in ['max_num_clusters']:\n",
    "                self._clusters = None\n",
    "            if param_name in ['expand_distance', 'expand_graph_distance', 'join_method']:\n",
    "                self._expanded_clusters = None\n",
    "        return parameter_changed\n",
    "\n",
    "    def _get_mean_curvature_mask(self):\n",
    "        if self._mean_curvature_mask is None:\n",
    "            self._mean_curvature_mask = (self.vertex_mean_curvature >= self.params['min_H']) & (self.vertex_mean_curvature <= self.params['max_H'])\n",
    "        return self._mean_curvature_mask\n",
    "    def _get_pc2_mask(self):\n",
    "        if self._pc2_mask is None:\n",
    "            if self.params['use_pc2']:\n",
    "                pc2_threshold = np.nanquantile(self.vertex_pc2_values, self.params['pc2_quantile'])\n",
    "                self._pc2_mask = self.vertex_pc2_values >= pc2_threshold\n",
    "            else:\n",
    "                self._pc2_mask = None\n",
    "        return self._pc2_mask\n",
    "    \n",
    "    def _compute_clusters(self):\n",
    "        if self._clusters is None:\n",
    "            mean_curvature_mask = self._get_mean_curvature_mask()\n",
    "            pc2_mask = self._get_pc2_mask()\n",
    "            if pc2_mask is not None:\n",
    "                combined_mask = mean_curvature_mask & pc2_mask\n",
    "            else:\n",
    "                combined_mask = mean_curvature_mask\n",
    "            subgraph = self.adj_graph.subgraph(np.argwhere(combined_mask).flatten())\n",
    "            sorted_components = sorted(list(nx.connected_components(subgraph)), key=lambda x: len(x), reverse=True)\n",
    "            if self.params['max_num_clusters'] is None or self.params['max_num_clusters'] == 0:\n",
    "                raise ValueError(\"Parameter 'max_num_clusters' must be a positive integer.\")\n",
    "            sorted_components = sorted_components[:self.params['max_num_clusters']]\n",
    "            self._clusters = [ np.array(list(comp)) for comp in  sorted_components ]\n",
    "        return self._clusters\n",
    "    \n",
    "    @staticmethod\n",
    "    def _expand_nodes(graph : nx.Graph, nodes, dist : int):\n",
    "        if dist <= 0:\n",
    "            return set(nodes)\n",
    "        inflated = set(nodes)\n",
    "        frontier = set(nodes)\n",
    "        for _ in range(dist):\n",
    "            next_frontier = set()\n",
    "            for node in frontier:\n",
    "                next_frontier.update(graph.neighbors(node))\n",
    "            next_frontier -= inflated\n",
    "            inflated.update(next_frontier)\n",
    "            frontier = next_frontier\n",
    "            if not frontier:\n",
    "                break\n",
    "        return inflated\n",
    "\n",
    "    def _expand_clusters(self):\n",
    "        clusters = self._compute_clusters()\n",
    "        if self._expanded_clusters is None:\n",
    "            self._expanded_clusters = []\n",
    "            for cluster in clusters:\n",
    "                \n",
    "                grown_cluster_by_distance = None\n",
    "                grown_cluster_by_graph_distance = None\n",
    "                if self.params['expand_distance'] > 0:\n",
    "                    grown_cluster_by_distance = set(cluster)\n",
    "                    indices = self.tree.query_ball_point(self.vertices[cluster], r=self.params['expand_distance'])\n",
    "                    for nearby_indices in indices:\n",
    "                        grown_cluster_by_distance.update(nearby_indices)\n",
    "                if self.params['expand_graph_distance'] > 0:\n",
    "                    grown_cluster_by_graph_distance = self._expand_nodes(self.adj_graph, cluster, self.params['expand_graph_distance'])\n",
    "\n",
    "                if self.params['join_method'] == 'and':\n",
    "                    if grown_cluster_by_distance is not None and grown_cluster_by_graph_distance is not None:\n",
    "                        final_cluster = grown_cluster_by_distance.intersection(grown_cluster_by_graph_distance)\n",
    "                    elif grown_cluster_by_distance is not None:\n",
    "                        final_cluster = grown_cluster_by_distance\n",
    "                    elif grown_cluster_by_graph_distance is not None:\n",
    "                        final_cluster = grown_cluster_by_graph_distance\n",
    "                    else:\n",
    "                        final_cluster = set(cluster)\n",
    "                elif self.params['join_method'] == 'or':\n",
    "                    final_cluster = set(cluster)\n",
    "                    if grown_cluster_by_distance is not None:\n",
    "                        final_cluster.update(grown_cluster_by_distance)\n",
    "                    if grown_cluster_by_graph_distance is not None:\n",
    "                        final_cluster.update(grown_cluster_by_graph_distance)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown join_method: {self.params['join_method']}\")\n",
    "                self._expanded_clusters.append(np.array(list(final_cluster)))\n",
    "            self._expanded_clusters = self._expanded_clusters\n",
    "        return self._expanded_clusters\n",
    "    \n",
    "    def run(self):\n",
    "        return self._expand_clusters()\n",
    "    \n",
    "    \n",
    "    def register_annotations(self, clusters_annotations : list):\n",
    "        if self._clusters is None or self._expanded_clusters is None:\n",
    "            raise ValueError(\"No clusters to export. Please run the segmentation first. We avoid automatic exports to prevent unintended data loss.\")\n",
    "        \n",
    "        \n",
    "        #annotations_dict = {}\n",
    "        #for annotation in clusters_annotations:\n",
    "        #    has_single_cluster = False\n",
    "        #    has_multiple_clusters = False\n",
    "        #    clusters = None\n",
    "        #    try:\n",
    "        #        clusters = [int(annotation)]\n",
    "        #        has_single_cluster  = True\n",
    "        #    except:\n",
    "        #        has_single_cluster = False\n",
    "#\n",
    "        #    try:\n",
    "        #        clusters = annotation.split('+')\n",
    "        #        clusters = [int(c) for c in clusters]\n",
    "        #        has_multiple_clusters = True\n",
    "        #    except:\n",
    "        #        has_multiple_clusters = False\n",
    "#\n",
    "        #    if not has_single_cluster and not has_multiple_clusters:\n",
    "        #        raise ValueError(f\"Invalid annotation format: {annotation}. Must be an integer or a '+'-separated list of integers.\")\n",
    "        #    \n",
    "        #    try:\n",
    "        #        annotated_vertices = np.unique(np.concatenate([ self._expanded_clusters[c] for c in clusters ]))\n",
    "        #    except IndexError:\n",
    "        #        raise ValueError(f\"Cluster index out of range in annotation: {annotation}. Available clusters: 0 to {len(self._expanded_clusters)-1}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad12b9af",
   "metadata": {},
   "source": [
    "## Load Meshes\n",
    "Meshes are loaded from a dict. The dict must contain an entry per mesh with an arbitrary name. Each entry must be a dict with at least a 'path' field, containing the path of the mesh.\n",
    "We also accept other fields in each mesh dictionary.\n",
    "The 'scale' key contains either a single float or a 3-tuple of floats to scale the vertices with.\n",
    "The 'invert_axis' is a boolean 3-tuple which if set inverts each axis of the mesh as:\n",
    "$$ x' = x_{\\rm max} + x_{\\rm min} - x$$\n",
    "Below we also visualize the meshes using Plotly. At the moment, one can modify manually the meshes by specifying which axes to invert (as above). This results in a new 'mesh_info_dict'. Note: to avoid confusion, we do NOT use the original invert_axis field. In other words, this is useful when no prior 'invert_axis' field is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "915f9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/Users/schimmenti/Desktop/DresdenProjects/wingsurface/final_meshes/wildtype/\")\n",
    "#base_dir = Path(\"/data/biophys/schimmenti/Repositories/wingsurface/final_meshes/wildtype/\")\n",
    "mesh_info_dict = {p.stem: {'path': str(p.absolute())} for p in base_dir.glob(\"*.ply\")}\n",
    "mesh_info_dict = {'20220517_ecadGFPnbG4_96hAEL_disc6_scale0.5_fused_surface_blender_split' : mesh_info_dict['20220517_ecadGFPnbG4_96hAEL_disc6_scale0.5_fused_surface_blender_split']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80696709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing mesh: 20220517_ecadGFPnbG4_96hAEL_disc6_scale0.5_fused_surface_blender_split: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "mesh_dataset = load_and_process_meshes(mesh_info_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663c683",
   "metadata": {},
   "source": [
    "### View processed meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0051583d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29285f063abb43f18bd2f7877f0895c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Sample', options=('20220517_ecadGFPnbG4_96hAEL_disc6_scale0.5_fused_surfa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52816b13b758486c96bb05b517b86c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'color': '#4C78A8',\n",
       "              'i': {'bdata': ('AQAAAPABAABrAgAAAQAAAOcCAADlAQ' ... 'AAABoAAAAYAAAAGQAAABQAAAATAAAA'),\n",
       "                    'dtype': 'i4'},\n",
       "              'j': {'bdata': ('5wEAAAIAAAACAAAA8AIAAPsDAADiAQ' ... 'AAABwAAAAXAAAAGgAAABYAAAAWAAAA'),\n",
       "                    'dtype': 'i4'},\n",
       "              'k': {'bdata': ('awIAAOwBAAABAAAA7wIAAPoDAABzAw' ... 'AAABcAAAAbAAAAFwAAABUAAAAUAAAA'),\n",
       "                    'dtype': 'i4'},\n",
       "              'name': 'Mesh',\n",
       "              'opacity': 0.5,\n",
       "              'type': 'mesh3d',\n",
       "              'uid': 'f28da9ec-cba9-42d8-be4c-f7b0949c8dec',\n",
       "              'x': {'bdata': ('RVsA4PmmWkDOUP3/D5FCQK0qAyBRWk' ... 'AAAAAEZUDb5gCgbgJlQBhE/18Q/GRA'),\n",
       "                    'dtype': 'f8'},\n",
       "              'y': {'bdata': ('f60BAFYyb0DYGgBgO/N7QG8MAcChJ3' ... 'j+3yLteED/mf9fDhd5QOOJ/7/KLXlA'),\n",
       "                    'dtype': 'f8'},\n",
       "              'z': {'bdata': ('y0UAYLpjckBPZP+fR3twQM4RAaDttn' ... 'UAgD9le0BeBQDg+1t7QJaLAMB0RXtA'),\n",
       "                    'dtype': 'f8'}}],\n",
       "    'layout': {'height': 400,\n",
       "               'legend': {'itemsizing': 'constant'},\n",
       "               'margin': {'b': 0, 'l': 50, 'r': 50, 't': 60},\n",
       "               'scene': {'aspectmode': 'data',\n",
       "                         'uirevision': 'keep',\n",
       "                         'xaxis': {'title': {'text': 'x'}},\n",
       "                         'yaxis': {'title': {'text': 'y'}},\n",
       "                         'zaxis': {'title': {'text': 'z'}}},\n",
       "               'template': '...',\n",
       "               'title': {'text': ''},\n",
       "               'width': 800}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "invert_axes_results = { name : mesh_info_dict[name].get('invert_axis', (False, False, False)) for name in mesh_dataset.keys() }\n",
    "def view_meshes():\n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(\n",
    "        title=\"\",\n",
    "        width=800, height=400,\n",
    "        scene=dict(\n",
    "            xaxis_title='x', yaxis_title='y', zaxis_title='z',\n",
    "            aspectmode='data',\n",
    "            uirevision=\"keep\"  # preserve camera/zoom\n",
    "        ),\n",
    "        margin=dict(l=50, r=50, t=60, b=0),\n",
    "        legend=dict(itemsizing='constant')\n",
    "    )\n",
    "    palette = px.colors.qualitative.T10\n",
    "    sample_id_widget = widgets.Dropdown(options=mesh_dataset.keys(), description='Sample')\n",
    "    close_button_widget = widgets.Button(description='Close')\n",
    "    tick_widgets = [widgets.Checkbox(description='Invert X'), \n",
    "                    widgets.Checkbox(description='Invert Y'), \n",
    "                    widgets.Checkbox(description='Invert Z')]\n",
    "    \n",
    "    ui = widgets.HBox([\n",
    "        sample_id_widget, *tick_widgets, close_button_widget])\n",
    "    def _replot():\n",
    "        fig.data = []\n",
    "        sample_id = sample_id_widget.value\n",
    "        vertices, triangles = mesh_dataset[sample_id]\n",
    "        mesh_trace = go.Mesh3d(\n",
    "            x=vertices[:, 0].max() + vertices[:, 0].min() - vertices[:, 0] if tick_widgets[0].value else vertices[:, 0],\n",
    "            y=vertices[:, 1].max() + vertices[:, 1].min() - vertices[:, 1] if tick_widgets[1].value else vertices[:, 1], \n",
    "            z=vertices[:, 2].max() + vertices[:, 2].min() - vertices[:, 2] if tick_widgets[2].value else vertices[:, 2],\n",
    "            i=triangles[:, 0],\n",
    "            j=triangles[:, 1],\n",
    "            k=triangles[:, 2],\n",
    "            color=palette[0],\n",
    "            opacity=0.5,\n",
    "            name='Mesh'\n",
    "        )\n",
    "        fig.add_trace(mesh_trace)\n",
    "\n",
    "    def on_tick_change(change):\n",
    "        invert_axes_results[sample_id_widget.value] = tuple(tick_widgets[i].value for i in range(3))\n",
    "        _replot()\n",
    "    \n",
    "    def _update_viewer(change):\n",
    "        if change is not None:\n",
    "            # we recover the previous settings\n",
    "            for i in range(3):\n",
    "                tick_widgets[i].unobserve_all()\n",
    "                tick_widgets[i].value = invert_axes_results[sample_id_widget.value][i]\n",
    "        for i in range(3):\n",
    "            tick_widgets[i].observe(on_tick_change, names='value')\n",
    "        \n",
    "        _replot()\n",
    "    \n",
    "    _update_viewer(None)\n",
    "    def on_sample_change(change):\n",
    "        _update_viewer(change)\n",
    "    sample_id_widget.observe(on_sample_change, names='value')\n",
    "    def on_close_button_clicked(b):\n",
    "        for _ in range(3):\n",
    "            invert_axes_results[sample_id_widget.value] = tuple(tick_widgets[i].value for i in range(3))\n",
    "        fig.close_all()\n",
    "    close_button_widget.on_click(on_close_button_clicked)\n",
    "    display(ui, fig)\n",
    "view_meshes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68873ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mesh_info_dict = {}\n",
    "for name, fields in mesh_info_dict.items():\n",
    "    new_fields = fields.copy()\n",
    "    new_fields['invert_axis'] = invert_axes_results[name]\n",
    "    new_mesh_info_dict[name] = new_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c524af1",
   "metadata": {},
   "source": [
    "## Segment folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a722e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.21s/it]\n"
     ]
    }
   ],
   "source": [
    "default_params_dict = {\n",
    "    'min_H': -1.0,\n",
    "    'max_H': -0.1,\n",
    "    'use_pc2': False,\n",
    "    'pc2_quantile': 0.0,\n",
    "    'max_num_clusters': 10,\n",
    "    'expand_distance': 5.0,\n",
    "    'expand_graph_distance': 0,\n",
    "    'join_method': 'or',\n",
    "}\n",
    "segmentation_results = {}\n",
    "for name, fields in tqdm.tqdm(mesh_info_dict.items()):\n",
    "    segmentation_results[name] = FoldSegmentation(default_params_dict,\n",
    "                                                    vertices=mesh_dataset[name][0],\n",
    "                                                    triangles=mesh_dataset[name][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5854ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fa1a32cc6c407fbd35875e86a4ca17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(HBox(children=(Dropdown(description='Sample', options=('20220517_ecadGFPnbG4_96hAEL_d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def segment_folds(\n",
    "        curvature_step : float = 0.01,\n",
    "        quantile_step : float = 0.01,\n",
    "        distance_step : float = 0.1,\n",
    "):\n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(\n",
    "        title=\"\",\n",
    "        width=800, height=680,\n",
    "        scene=dict(\n",
    "            xaxis_title='x', yaxis_title='y', zaxis_title='z',\n",
    "            aspectmode='data',\n",
    "            uirevision=\"keep\"  # preserve camera/zoom\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "        legend=dict(itemsizing='constant')\n",
    "    )\n",
    "    fig.layout.legend.y = 0.5\n",
    "    palette = px.colors.qualitative.T10\n",
    "    sample_id_widget = widgets.Dropdown(options=mesh_dataset.keys(), description='Sample')\n",
    "    show_hide_clusters_widget = widgets.Checkbox(value=True, description='Show/Hide Clusters')\n",
    "    show_hide_curvature_widget = widgets.Checkbox(value=False, description='Show/Hide Curvature')\n",
    "    min_H_widget = widgets.FloatText(value=default_params_dict['min_H'], description='Min H', step=curvature_step)\n",
    "    max_H_widget = widgets.FloatText(value=default_params_dict['max_H'], description='Max H', step=curvature_step)\n",
    "    use_pc2_widget = widgets.Checkbox(value=default_params_dict['use_pc2'], description='Use PC2')\n",
    "    pc2_quantile_widget = widgets.BoundedFloatText(value=default_params_dict['pc2_quantile'], description='PC2 Quantile', step=quantile_step, min=0.0, max=1.0)\n",
    "    max_num_clusters_widget = widgets.BoundedIntText(value=default_params_dict['max_num_clusters'], description='Num Clusters', min=1)\n",
    "    expand_distance_widget = widgets.BoundedFloatText(value=default_params_dict['expand_distance'],  description='Expand Distance', step=distance_step, min=0.0)\n",
    "    expand_graph_distance_widget = widgets.BoundedIntText(value=default_params_dict['expand_graph_distance'], description='Expand Graph Distance', min=0)\n",
    "    join_method_widget = widgets.Dropdown(options=['and', 'or'], value=default_params_dict['join_method'], description='Join Method')\n",
    "    #text_selection_widget = widgets.Text(value='', description='Clusters',\n",
    "    #                                     tooltip=\"Save cluster indices as comma-separated values, e.g. 0,2,5. You can merge clusters using '+', e.g. [0+1,2,5].\")\n",
    "    #text_selection_widget.layout.pointer_events = \"auto\"\n",
    "    clusters_selection_widget = widgets.TagsInput(value=[],allow_duplicates=False)\n",
    "    close_button_widget = widgets.Button(description='Close')\n",
    "\n",
    "    row1_widget = widgets.HBox(\n",
    "        [sample_id_widget, widgets.HBox([ widgets.Label(\"Cluster IDs\", tooltip=\"Save cluster indices as comma-separated values, e.g. 0,2,5. You can merge clusters using '+', e.g. [0+1,2,5].\"),\n",
    "                                           clusters_selection_widget]), \n",
    "                                           close_button_widget],\n",
    "        layout=widgets.Layout(width=\"100%\", justify_content=\"space-between\", align_items=\"center\")\n",
    "    )\n",
    "    \n",
    "    row2_left_widget = widgets.VBox([\n",
    "        show_hide_clusters_widget,\n",
    "        show_hide_curvature_widget,\n",
    "        min_H_widget, max_H_widget,\n",
    "        use_pc2_widget, pc2_quantile_widget,\n",
    "        max_num_clusters_widget,\n",
    "        expand_distance_widget,\n",
    "        expand_graph_distance_widget,\n",
    "        join_method_widget\n",
    "    ])\n",
    "    \n",
    "    # Box is better than VBox for “just a figure”\n",
    "    row2_right_widget = widgets.Box(\n",
    "        [fig],\n",
    "        layout=widgets.Layout(width=\"100%\", height=\"100%\", overflow=\"visible\")\n",
    "    )\n",
    "    \n",
    "\n",
    "    # -----------------------------\n",
    "    grid = widgets.GridspecLayout(2, 2, width=\"100%\", grid_gap=\"12px\")\n",
    "    \n",
    "    grid[0, :] = row1_widget\n",
    "    grid[1, 0] = row2_left_widget\n",
    "    grid[1, 1] = row2_right_widget\n",
    "\n",
    "    grid.layout.grid_template_columns = \"320px 1fr\"\n",
    "    grid.layout.grid_template_rows = \"auto 1fr\"\n",
    "    grid.layout.align_items = \"flex-start\"\n",
    "    \n",
    "    row2_left_widget.layout = widgets.Layout(\n",
    "        width=\"100%\",\n",
    "        height=\"680px\",\n",
    "        overflow_y=\"auto\",\n",
    "        overflow_x=\"hidden\",\n",
    "        align_self=\"flex-start\"\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    row2_right_widget.layout = widgets.Layout(\n",
    "        width=\"100%\",\n",
    "        height=\"680px\",\n",
    "        align_self=\"stretch\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _plot_mesh(delete_all):\n",
    "        if delete_all:\n",
    "            fig.data = []\n",
    "        else:\n",
    "            fig.data = tuple(t for t in fig.data if t.name != 'mesh')\n",
    "        sample_id = sample_id_widget.value\n",
    "        vertices, triangles = mesh_dataset[sample_id]\n",
    "        mesh_trace = go.Mesh3d(\n",
    "            x=vertices[:, 0],\n",
    "            y=vertices[:, 1], \n",
    "            z=vertices[:, 2],\n",
    "            i=triangles[:, 0],\n",
    "            j=triangles[:, 1],\n",
    "            k=triangles[:, 2],\n",
    "            color=palette[0],\n",
    "            opacity=0.5,\n",
    "            name='mesh'\n",
    "        )\n",
    "        if show_hide_curvature_widget.value:\n",
    "            mesh_trace.intensity = segmentation_results[sample_id].vertex_mean_curvature\n",
    "            mesh_trace.colorscale = 'RdBu'\n",
    "            mesh_trace.cmid = 0.0\n",
    "            mesh_trace.cmin, mesh_trace.cmax = np.nanquantile(segmentation_results[sample_id].vertex_mean_curvature, [0.05, 0.95])\n",
    "            mesh_trace.colorbar.x = 0.95\n",
    "            mesh_trace.colorbar.y = 0.5\n",
    "        else:\n",
    "            mesh_trace.intensity = None\n",
    "        fig.add_trace(mesh_trace)\n",
    "\n",
    "    def _show_hide_clusters(b):\n",
    "        for trace in fig.data:\n",
    "            if 'cluster' in trace.name:\n",
    "                if show_hide_clusters_widget.value:\n",
    "                    trace.visible = True\n",
    "                else:\n",
    "                    trace.visible = False\n",
    "        \n",
    "    def _plot_clusters():\n",
    "        name = sample_id_widget.value\n",
    "        segmentation = segmentation_results[name]\n",
    "        expanded_clusters = segmentation.run()\n",
    "        if len(fig.data) > 0:\n",
    "            fig.data = tuple(t for t in fig.data if 'cluster' not in t.name)\n",
    "        for i, exanded_cluster in enumerate(expanded_clusters):\n",
    "            cluster_trace = go.Scatter3d(\n",
    "                x=segmentation.vertices[exanded_cluster, 0],\n",
    "                y=segmentation.vertices[exanded_cluster, 1],\n",
    "                z=segmentation.vertices[exanded_cluster, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(size=2, color=palette[(i % (len(palette)-1)) + 1]),\n",
    "                name=f'cluster_{i}'\n",
    "            )\n",
    "            cluster_trace.visible = True if show_hide_clusters_widget.value else False\n",
    "            fig.add_trace(cluster_trace)\n",
    "        \n",
    "        \n",
    "    def _on_parameter_change(change):\n",
    "        name = sample_id_widget.value\n",
    "        segmentation = segmentation_results[name]\n",
    "        segmentation.update_parameter('min_H', min_H_widget.value)\n",
    "        segmentation.update_parameter('max_H', max_H_widget.value)\n",
    "        segmentation.update_parameter('use_pc2', use_pc2_widget.value)\n",
    "        segmentation.update_parameter('pc2_quantile', pc2_quantile_widget.value)\n",
    "        segmentation.update_parameter('max_num_clusters', max_num_clusters_widget.value)\n",
    "        segmentation.update_parameter('expand_distance', expand_distance_widget.value)\n",
    "        segmentation.update_parameter('expand_graph_distance', expand_graph_distance_widget.value)\n",
    "        segmentation.update_parameter('join_method', join_method_widget.value)\n",
    "        _plot_clusters()\n",
    "\n",
    "        \n",
    "\n",
    "    for widget in [min_H_widget, max_H_widget, use_pc2_widget, pc2_quantile_widget, max_num_clusters_widget,\n",
    "                   expand_distance_widget, expand_graph_distance_widget, join_method_widget]:\n",
    "        widget.observe(_on_parameter_change, names='value')\n",
    "    \n",
    "    \n",
    "    show_hide_clusters_widget.observe(_show_hide_clusters, names='value')\n",
    "    show_hide_curvature_widget.observe(lambda change: _plot_mesh(False), names='value')\n",
    "\n",
    "    _plot_mesh(True)\n",
    "    _plot_clusters()\n",
    "\n",
    "    def _on_sample_change(change):\n",
    "        if change is not None:\n",
    "            name = sample_id_widget.value\n",
    "            segmentation = segmentation_results[name]\n",
    "            #show_hide_clusters_widget.value = True\n",
    "            #show_hide_curvature_widget.value = False\n",
    "            min_H_widget.value = segmentation.params['min_H']\n",
    "            max_H_widget.value = segmentation.params['max_H']\n",
    "            use_pc2_widget.value = segmentation.params['use_pc2']\n",
    "            pc2_quantile_widget.value = segmentation.params['pc2_quantile']\n",
    "            max_num_clusters_widget.value = segmentation.params['max_num_clusters']\n",
    "            expand_distance_widget.value = segmentation.params['expand_distance']\n",
    "            expand_graph_distance_widget.value = segmentation.params['expand_graph_distance']\n",
    "            join_method_widget.value = segmentation.params['join_method']\n",
    "            _plot_mesh(True)\n",
    "            _plot_clusters()\n",
    "    sample_id_widget.observe(_on_sample_change, names='value')\n",
    "\n",
    "    display(grid)\n",
    "segment_folds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2daeac",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52183a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normals_as_lineset(\n",
    "    mesh: o3d.geometry.TriangleMesh,\n",
    "    scale: float = 0.05,\n",
    "):\n",
    "    V = np.asarray(mesh.vertices)\n",
    "    N = np.asarray(mesh.vertex_normals)\n",
    "\n",
    "    # start points\n",
    "    P0 = V\n",
    "    # end points\n",
    "    P1 = V + scale * N\n",
    "\n",
    "    points = np.vstack([P0, P1])\n",
    "    n = len(V)\n",
    "\n",
    "    lines = np.array([[i, i + n] for i in range(n)], dtype=np.int32)\n",
    "\n",
    "    colors = np.tile([[1.0, 0.0, 0.0]], (len(lines), 1))  # red\n",
    "\n",
    "    ls = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "    )\n",
    "    ls.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    return ls\n",
    "mesh = load_mesh(file_path=mesh_list[0], scale=1.0, invert_axis=(False, False, False), orient_by_centroid=True, return_as_numpy=False)\n",
    "#o3d.visualization.draw_plotly([mesh, normals_as_lineset(mesh, scale=5.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3f1b0",
   "metadata": {},
   "source": [
    "### Load Meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c818729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/Users/schimmenti/Desktop/DresdenProjects/wingsurface/final_meshes/wildtype/\")\n",
    "#base_dir = Path(\"meshes/\")\n",
    "json_file_with_infos = base_dir.joinpath(\"mesh_infos.json\")\n",
    "mesh_infos_dict = json.load(open(json_file_with_infos))\n",
    "mesh_infos_dict = { identifier : info for identifier, info in sorted(mesh_infos_dict.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mesh(mesh_info):\n",
    "    scale = mesh_info['scale'] if 'scale' in mesh_info else 1.0\n",
    "    flip0 = mesh_info['flip0'] if 'flip0' in mesh_info else False\n",
    "    flip1 = mesh_info['flip1'] if 'flip1' in mesh_info else False\n",
    "    flip2 = mesh_info['flip2'] if 'flip2' in mesh_info else False\n",
    "    vertices, triangles  = load_and_process_mesh(base_dir.joinpath(mesh_info['filename']), scale=scale, flip0=flip0, flip1=flip1, flip2=flip2, return_as_open3d_mesh=False)\n",
    "    vertex_normals = igl.per_vertex_normals(vertices, triangles)\n",
    "    triangles, vertex_normals = orient_centroid(vertices, triangles, vertex_normals)\n",
    "    #if(loaded_mesh.is_vertex_manifold()==False):\n",
    "    #    print(f\"Mesh {mesh_identifier} is not vertex manifold!\")\n",
    "    #if(loaded_mesh.is_edge_manifold()==False):\n",
    "    #    print(f\"Mesh {mesh_identifier} is not edge manifold!\")\n",
    "    #vertices, triangles = np.asarray(loaded_mesh.vertices), np.asarray(loaded_mesh.triangles)\n",
    "    adjList = igl.adjacency_list(triangles)\n",
    "    adjGraph = nx.from_dict_of_lists({ i : list(adjList[i])  for i in range(len(adjList))})\n",
    "    cotmatrix = igl.cotmatrix(vertices, triangles)\n",
    "    massmatrix = igl.massmatrix(vertices, triangles, igl.MASSMATRIX_TYPE_VORONOI)\n",
    "    \n",
    "    laplacian = sp.linalg.inv(massmatrix) @ cotmatrix\n",
    "    mean_curvature = np.sum((laplacian @ vertices)*vertex_normals, axis=1)\n",
    "    pc_res = igl.principal_curvature(vertices, triangles)[:4]\n",
    "    mesh_dict = {}\n",
    "    mesh_dict['vertices'] = vertices\n",
    "    mesh_dict['triangles'] = triangles\n",
    "    #mesh_dict['adjList'] = adjList\n",
    "    mesh_dict['adjGraph'] = adjGraph\n",
    "    mesh_dict['cotmatrix'] = cotmatrix\n",
    "    mesh_dict['massmatrix'] = massmatrix\n",
    "    mesh_dict['laplacian'] = laplacian\n",
    "    mesh_dict['vertex_normals'] = vertex_normals\n",
    "    mesh_dict['mean_curvature'] = mean_curvature\n",
    "    mesh_dict['principal_curvature_1'] = pc_res[2]\n",
    "    mesh_dict['principal_curvature_2'] = pc_res[3]\n",
    "    return mesh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes_dict = {}\n",
    "for mesh_identifier, mesh_info in mesh_infos_dict.items():\n",
    "    scale = mesh_info['scale'] if 'scale' in mesh_info else 1.0\n",
    "    flip0 = mesh_info['flip0'] if 'flip0' in mesh_info else False\n",
    "    flip1 = mesh_info['flip1'] if 'flip1' in mesh_info else False\n",
    "    flip2 = mesh_info['flip2'] if 'flip2' in mesh_info else False\n",
    "    mesh_dict = load_mesh(mesh_info)\n",
    "    meshes_dict[mesh_identifier] = mesh_dict\n",
    "    vertices = mesh_dict['vertices']\n",
    "    triangles = mesh_dict['triangles']\n",
    "    normals = mesh_dict['vertex_normals']\n",
    "    mean_curvature = mesh_dict['mean_curvature']\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(vertices[:, 1], vertices[:, 2], vertices[:, 0], c=mean_curvature, cmap='seismic', vmin=-0.1, vmax=0.1)\n",
    "    #ax.quiver(vertices[::50, 1], vertices[::50, 2], vertices[::50, 0], normals[::50, 1], normals[::50, 2], normals[::50, 0], length=20, color='black')\n",
    "    ax.set_title(';'.join([mesh_identifier, str(flip0), str(flip1), str(flip2), str(scale)]))\n",
    "    ax.set_aspect('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be20d4",
   "metadata": {},
   "source": [
    "### Annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_keys = list(mesh_infos_dict.keys())\n",
    "exported_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_component(graph : nx.Graph, nodes, dist : int):\n",
    "    if dist <= 0:\n",
    "        return set(nodes)\n",
    "    inflated = set(nodes)\n",
    "    frontier = set(nodes)\n",
    "    for _ in range(dist):\n",
    "        next_frontier = set()\n",
    "        for node in frontier:\n",
    "            next_frontier.update(graph.neighbors(node))\n",
    "        next_frontier -= inflated\n",
    "        inflated.update(next_frontier)\n",
    "        frontier = next_frontier\n",
    "        if not frontier:\n",
    "            break\n",
    "    return inflated\n",
    "class MeshSegmentation:\n",
    "    def __init__(self, vertices, triangles, adjGraph, mean_curvature, principal_curvature_1, principal_curvature_2):\n",
    "        self.vertices = vertices\n",
    "        self.triangles = triangles\n",
    "        self.adjGraph = adjGraph\n",
    "        self.mean_curvature = mean_curvature\n",
    "        self.principal_curvature_1 = principal_curvature_1\n",
    "        self.principal_curvature_2 = principal_curvature_2\n",
    "        self.principal_curvature_2_percentiles = np.percentile(self.principal_curvature_2, np.arange(0, 101, 1))\n",
    "        self.num_vertices = len(vertices)\n",
    "        self.H_min_mask = np.ones(self.num_vertices, dtype=bool)\n",
    "        self.H_max_mask = np.ones(self.num_vertices, dtype=bool)\n",
    "        self.H_min = np.inf\n",
    "        self.H_max = -np.inf\n",
    "        self.pc2_mask = np.ones(self.num_vertices, dtype=bool)\n",
    "        self.pc2_percentile = 0\n",
    "        self.inflate_dist = 0\n",
    "        self.clusters = []\n",
    "        self.inflated_clusters = []\n",
    "        self.num_clusters = 0\n",
    "        \n",
    "    \n",
    "    def update(self, H_min : float, H_max : float, pc2_percentile : float, inflate_dist : int):\n",
    "        needs_update = False\n",
    "        if(H_min is not None and H_min!=self.H_min):\n",
    "            needs_update = True\n",
    "            self.H_min = H_min\n",
    "            self.H_min_mask = self.mean_curvature >= self.H_min\n",
    "        elif(H_min is None):\n",
    "            self.H_min_mask = np.ones(self.num_vertices, dtype=bool)\n",
    "        if(H_max is not None and H_max!=self.H_max):\n",
    "            needs_update = True\n",
    "            self.H_max = H_max\n",
    "            self.H_max_mask = self.mean_curvature <= self.H_max\n",
    "        elif(H_max is None):\n",
    "            self.H_max_mask = np.ones(self.num_vertices, dtype=bool)\n",
    "        if(pc2_percentile is not None):\n",
    "            int_pc2_percentile = min(max(int(pc2_percentile), 0),100)\n",
    "            if(int_pc2_percentile!=self.pc2_percentile):\n",
    "                needs_update = True\n",
    "                self.pc2_percentile = int_pc2_percentile\n",
    "                self.pc2_mask = self.principal_curvature_2 < self.principal_curvature_2_percentiles[self.pc2_percentile]\n",
    "        elif(pc2_percentile is None):\n",
    "            self.pc2_mask = np.ones(self.num_vertices, dtype=bool)\n",
    "        if(inflate_dist is not None):\n",
    "            if(inflate_dist != self.inflate_dist):\n",
    "                needs_update = True\n",
    "                self.inflate_dist = inflate_dist            \n",
    "        if(needs_update):\n",
    "            mask = self.H_min_mask & self.H_max_mask & self.pc2_mask\n",
    "            subgraph = self.adjGraph.subgraph(np.where(mask)[0])\n",
    "            found_clusters = sorted(list(nx.connected_components(subgraph)), key=len, reverse=True)\n",
    "            self.clusters.clear()\n",
    "            self.inflated_clusters.clear()\n",
    "            self.num_clusters = len(found_clusters)\n",
    "            self.clusters = [np.array(list(cluster)) for cluster in found_clusters]\n",
    "            for i, cluster in enumerate(found_clusters):\n",
    "                inflated = inflate_component(self.adjGraph, cluster, self.inflate_dist)\n",
    "                self.inflated_clusters.append(np.array(list(inflated)))\n",
    "    def import_params(self, import_dict):\n",
    "        self.H_min = import_dict['H_min']\n",
    "        self.H_max = import_dict['H_max']\n",
    "        self.pc2_percentile = import_dict['pc2_percentile']\n",
    "        self.inflate_dist = import_dict['inflate_dist']\n",
    "        self.update(self.H_min, self.H_max, self.pc2_percentile, self.inflate_dist)\n",
    "    def export_params(self):\n",
    "        export_dict = {}\n",
    "        export_dict['clusters'] = [ cluster.tolist() for cluster in self.clusters]\n",
    "        export_dict['inflated_clusters'] = [ cluster.tolist() for cluster in self.inflated_clusters]\n",
    "        export_dict['H_min'] = self.H_min\n",
    "        export_dict['H_max'] = self.H_max\n",
    "        export_dict['pc2_percentile'] = self.pc2_percentile\n",
    "        export_dict['inflate_dist'] = self.inflate_dist\n",
    "        return export_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c26ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_segmentation = None\n",
    "current_sample_id = None\n",
    "\n",
    "sample_id_widget = widgets.Dropdown(options=file_keys, description='Sample')\n",
    "use_pc2_widget = widgets.Checkbox(value=True, description='Use k2')\n",
    "pc2_percentile_widget = widgets.IntSlider(value=20, min=0, max=100, step=1, description='k2 perc.')\n",
    "use_mean_curv_widget = widgets.Checkbox(value=True, description='Use H')\n",
    "mean_curv_min_widget = widgets.FloatText(value=0.1, description='H min')\n",
    "mean_curv_max_widget = widgets.FloatText(value=3.0, description='H max')\n",
    "num_comps_widget = widgets.IntText(value=10, description='Num comps', disabled=True)\n",
    "inflate_dist_widget = widgets.IntText(value=0, description='Inflate')\n",
    "\n",
    "fig = go.FigureWidget()\n",
    "fig.update_layout(\n",
    "    title=\"\",\n",
    "    width=800, height=700,\n",
    "    scene=dict(\n",
    "        xaxis_title='y', yaxis_title='z', zaxis_title='x',\n",
    "        aspectmode='data',\n",
    "        uirevision=\"keep\"  # preserve camera/zoom\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=60, b=0),\n",
    "    legend=dict(itemsizing='constant')\n",
    ")\n",
    "palette = px.colors.qualitative.T10\n",
    "\n",
    "\n",
    "\n",
    "# --- Helper: restore params/annotations for a sample (if we have them) ---\n",
    "def _apply_saved_params_for_sample(sid):\n",
    "    return\n",
    "\n",
    "# --- Main recompute/draw (reads current widget values) ---\n",
    "def update_plot(*_):\n",
    "    global mesh_segmentation, current_sample_id\n",
    "    sample_id      = sample_id_widget.value\n",
    "    use_pc2        = use_pc2_widget.value\n",
    "    pc2_percentile = pc2_percentile_widget.value\n",
    "    use_mean_curv  = use_mean_curv_widget.value\n",
    "    mean_curv_min  = mean_curv_min_widget.value\n",
    "    mean_curv_max  = mean_curv_max_widget.value\n",
    "    inflate_dist   = inflate_dist_widget.value\n",
    "    num_comps = num_comps_widget.value\n",
    "\n",
    "    # we need to load the mesh if it's a new sample\n",
    "    redraw_needed = False\n",
    "    if current_sample_id is None or sample_id != current_sample_id:\n",
    "        if(mesh_segmentation is not None):\n",
    "            # export params for previous sample\n",
    "            exported_params[current_sample_id] = mesh_segmentation.export_params()\n",
    "        #mesh_dict = load_mesh(mesh_infos_dict[sample_id])\n",
    "        mesh_dict = meshes_dict[sample_id]\n",
    "        vertices = mesh_dict['vertices']\n",
    "        triangles = mesh_dict['triangles']\n",
    "        adjGraph = mesh_dict['adjGraph']\n",
    "        mean_curvature = mesh_dict['mean_curvature']\n",
    "        principal_curvature_1 = mesh_dict['principal_curvature_1']\n",
    "        principal_curvature_2 = mesh_dict['principal_curvature_2']\n",
    "        mesh_segmentation = MeshSegmentation(vertices, triangles, adjGraph, mean_curvature, principal_curvature_1, principal_curvature_2)\n",
    "        \n",
    "        current_sample_id = sample_id\n",
    "        redraw_needed = True\n",
    "    else:\n",
    "        vertices = mesh_segmentation.vertices\n",
    "    \n",
    "    mesh_segmentation.update(\n",
    "            H_min = mean_curv_min if use_mean_curv else None,\n",
    "            H_max = mean_curv_max if use_mean_curv else None,\n",
    "            pc2_percentile = pc2_percentile if use_pc2 else None,\n",
    "            inflate_dist = inflate_dist\n",
    "        )\n",
    "    \n",
    "    \n",
    "\n",
    "    # Draw: keep mesh persistent; rebuild only clusters/rings\n",
    "    with fig.batch_update():\n",
    "        if redraw_needed:\n",
    "            # rebuild background mesh once for this sample\n",
    "            fig.data = []  # clear everything\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=vertices[:, 1], y=vertices[:, 2], z=vertices[:, 0],\n",
    "                mode='markers',\n",
    "                marker=dict(size=1, opacity=0.5, color='gray'),\n",
    "                name='Mesh'\n",
    "            ))\n",
    "        else:\n",
    "            # keep only the mesh trace; drop old clusters/rings\n",
    "            fig.data = fig.data[:1]\n",
    "\n",
    "        for i, comp in enumerate(mesh_segmentation.clusters[:num_comps]):\n",
    "            inflated_comp = mesh_segmentation.inflated_clusters[i] \n",
    "            color = palette[i % len(palette)]\n",
    "            # core\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=vertices[comp, 1], y=vertices[comp, 2], z=vertices[comp, 0],\n",
    "                mode='markers',\n",
    "                marker=dict(size=4, color=color, symbol='circle'),\n",
    "                name=f'Cluster {i} ({len(comp)})',\n",
    "                legendgroup=f'c{i}',\n",
    "                showlegend=True\n",
    "            ))\n",
    "            enlarged_only = np.setdiff1d(inflated_comp, comp)\n",
    "            if enlarged_only.size > 0:\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=vertices[enlarged_only, 1], y=vertices[enlarged_only, 2], z=vertices[enlarged_only, 0],\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=5, symbol='x', color=color),\n",
    "                    name=f'Ring {i} (+{len(enlarged_only)})',\n",
    "                    legendgroup=f'c{i}',\n",
    "                    showlegend=True\n",
    "                ))\n",
    "    \n",
    "        fig.update_layout(\n",
    "            scene_camera=fig.layout.scene.camera or dict(eye=dict(x=0.0, y=0.0, z=2.5))\n",
    "        )\n",
    "\n",
    "# --- Wire observers explicitly (no interactive_output) ---\n",
    "_suppress = {\"v\": False}\n",
    "\n",
    "def _on_any_param_change(change):\n",
    "    if not _suppress[\"v\"]:\n",
    "        update_plot()\n",
    "\n",
    "def _bind_param(w):\n",
    "    w.observe(_on_any_param_change, names='value')\n",
    "\n",
    "for w in [\n",
    "    use_pc2_widget, pc2_percentile_widget, use_mean_curv_widget,\n",
    "    mean_curv_min_widget, mean_curv_max_widget,\n",
    "    inflate_dist_widget\n",
    "]:\n",
    "    _bind_param(w)\n",
    "\n",
    "def on_sample_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        sid = change['new']\n",
    "        # Temporarily suppress reactive updates while restoring widgets\n",
    "        _suppress[\"v\"] = True\n",
    "        _apply_saved_params_for_sample(sid)  # restore if available\n",
    "        _suppress[\"v\"] = False\n",
    "        update_plot()  # recompute once with restored params\n",
    "\n",
    "sample_id_widget.observe(on_sample_change, names='value')\n",
    "\n",
    "# --- UI layout & initial draw ---\n",
    "ui = widgets.VBox([\n",
    "    sample_id_widget,\n",
    "    widgets.HBox([use_pc2_widget, pc2_percentile_widget]),\n",
    "    widgets.HBox([use_mean_curv_widget, mean_curv_min_widget, mean_curv_max_widget]),\n",
    "    widgets.HBox([inflate_dist_widget])\n",
    "])\n",
    "\n",
    "display(ui, fig)\n",
    "\n",
    "# If the initial sample has saved params, restore them first\n",
    "_suppress[\"v\"] = True\n",
    "_apply_saved_params_for_sample(sample_id_widget.value)\n",
    "_suppress[\"v\"] = False\n",
    "\n",
    "update_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flywings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
