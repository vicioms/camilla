{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import inspect\n",
    "import tqdm\n",
    "from typing import Any, Optional, Dict, List, Tuple, Callable, Union\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sparse\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import igl\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_mesh_open3d(mesh: o3d.geometry.TriangleMesh) -> o3d.geometry.TriangleMesh:\n",
    "    ret_mesh = mesh.remove_duplicated_triangles()\n",
    "    ret_mesh = ret_mesh.remove_duplicated_vertices()\n",
    "    ret_mesh = ret_mesh.remove_degenerate_triangles()\n",
    "    ret_mesh = ret_mesh.remove_non_manifold_edges()\n",
    "    ret_mesh = ret_mesh.remove_unreferenced_vertices()\n",
    "\n",
    "    # Keep only the largest connected component\n",
    "    clusters, lengths, _ = ret_mesh.cluster_connected_triangles()\n",
    "    clusters = np.asarray(clusters)\n",
    "    lengths = np.asarray(lengths)\n",
    "    largest_cluster = np.argmax(lengths)\n",
    "    ret_mesh.remove_triangles_by_index(\n",
    "        np.where(clusters != largest_cluster)[0]\n",
    "    )\n",
    "    ret_mesh = ret_mesh.remove_unreferenced_vertices()\n",
    "\n",
    "    # Remove non-manifold vertices\n",
    "    nm_verts = ret_mesh.get_non_manifold_vertices()\n",
    "    if len(nm_verts) > 0:\n",
    "        ret_mesh.remove_vertices_by_index(nm_verts)\n",
    "\n",
    "    # Final clean-up\n",
    "    ret_mesh = ret_mesh.remove_non_manifold_edges()\n",
    "    ret_mesh = ret_mesh.remove_unreferenced_vertices()\n",
    "    return ret_mesh\n",
    "def _orient_mesh_by_centroid(vertices : np.ndarray,\n",
    "                             triangles : np.ndarray,\n",
    "                             vertex_normals : np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    flip = np.mean((vertices - vertices.mean(axis=0, keepdims=True))*vertex_normals > 0) < 0.5\n",
    "    if flip:\n",
    "        triangles = triangles[:, [2, 1, 0]]\n",
    "        if vertex_normals is not None:\n",
    "            vertex_normals = -vertex_normals\n",
    "    return triangles, vertex_normals\n",
    "def _process_mesh(\n",
    "    mesh: Optional[o3d.geometry.TriangleMesh] = None,\n",
    "    vertices: Optional[np.ndarray] = None,\n",
    "    triangles: Optional[np.ndarray] = None,\n",
    "    scale: Union[float, Tuple[float, float, float]] = 1.0,\n",
    "    invert_axis: Tuple[bool, bool, bool] = (False, False, False),\n",
    "    mesh_clean_pipeline: Callable = _clean_mesh_open3d,\n",
    "    mesh_clean_pipeline_params: Optional[Dict] = None,\n",
    "    orient_by_centroid: bool = False,\n",
    "    return_as_numpy: bool = False,\n",
    "):\n",
    "    # --- get V,F as numpy ---\n",
    "    if mesh is None:\n",
    "        if vertices is None or triangles is None:\n",
    "            raise ValueError(\"Either mesh or both vertices and triangles must be provided.\")\n",
    "        V = np.asarray(vertices, dtype=np.float64).copy()\n",
    "        F = np.asarray(triangles, dtype=np.int32).copy()\n",
    "        mesh = o3d.geometry.TriangleMesh()\n",
    "    else:\n",
    "        V = np.asarray(mesh.vertices).copy()\n",
    "        F = np.asarray(mesh.triangles).copy()\n",
    "\n",
    "    # --- preprocess in numpy ---\n",
    "    if scale != 1.0:\n",
    "        if isinstance(scale, (int, float)):\n",
    "            V *= scale\n",
    "        else:\n",
    "            V *= np.array(scale)\n",
    "\n",
    "    for axis, inv in enumerate(invert_axis):\n",
    "        if inv:\n",
    "            mn, mx = V[:, axis].min(), V[:, axis].max()\n",
    "            V[:, axis] = (mx + mn) - V[:, axis]\n",
    "\n",
    "    # odd number of reflections => flip winding\n",
    "    if sum(bool(x) for x in invert_axis) % 2 == 1:\n",
    "        F = F[:, [0, 2, 1]]\n",
    "\n",
    "    # --- write back before normals/orientation ---\n",
    "    mesh.vertices = o3d.utility.Vector3dVector(V)\n",
    "    mesh.triangles = o3d.utility.Vector3iVector(F)\n",
    "\n",
    "    # now normals correspond to the current geometry\n",
    "    mesh.compute_vertex_normals()\n",
    "    N = np.asarray(mesh.vertex_normals)\n",
    "\n",
    "    if orient_by_centroid:\n",
    "        F2, N2 = _orient_mesh_by_centroid(V, F, N)\n",
    "        F = F2\n",
    "        # write updated triangles and recompute normals (safest)\n",
    "        mesh.triangles = o3d.utility.Vector3iVector(F)\n",
    "        mesh.compute_vertex_normals()\n",
    "        N = np.asarray(mesh.vertex_normals)\n",
    "\n",
    "\n",
    "    if mesh_clean_pipeline is not None:\n",
    "        params = dict(mesh_clean_pipeline_params or {})\n",
    "        sig = inspect.signature(mesh_clean_pipeline)\n",
    "\n",
    "        has_var_kwargs = any(\n",
    "            p.kind == inspect.Parameter.VAR_KEYWORD\n",
    "            for p in sig.parameters.values()\n",
    "        )\n",
    "\n",
    "        if not has_var_kwargs:\n",
    "            # filter params\n",
    "            params = {k: v for k, v in params.items() if k in sig.parameters}\n",
    "\n",
    "        # inject core objects if accepted and not already provided\n",
    "        if 'mesh' in sig.parameters and 'mesh' not in params:\n",
    "            params['mesh'] = mesh\n",
    "        if 'vertices' in sig.parameters and 'vertices' not in params:\n",
    "            params['vertices'] = V\n",
    "        if 'triangles' in sig.parameters and 'triangles' not in params:\n",
    "            params['triangles'] = F\n",
    "\n",
    "        mesh = mesh_clean_pipeline(**params)\n",
    "\n",
    "\n",
    "    if return_as_numpy:\n",
    "        return np.asarray(mesh.vertices), np.asarray(mesh.triangles)\n",
    "    return mesh\n",
    "def _load_and_process_mesh(file_path : str | Path, scale : float = 1.0, invert_axis : Tuple[bool, bool, bool] = (False, False, False), orient_by_centroid: bool = False, return_as_numpy: bool = False) -> Union[o3d.geometry.TriangleMesh, Tuple[np.ndarray, np.ndarray]]:\n",
    "    mesh = o3d.io.read_triangle_mesh(str(file_path))\n",
    "    return _process_mesh(mesh=mesh,\n",
    "                            scale=scale,\n",
    "                            invert_axis=invert_axis,\n",
    "                            mesh_clean_pipeline=_clean_mesh_open3d,\n",
    "                            orient_by_centroid=orient_by_centroid, return_as_numpy=return_as_numpy)\n",
    "def load_and_process_meshes(mesh_info_dict : Union[Dict[Any, dict]], verbose : bool = False) -> Dict[Any, Tuple[np.ndarray, np.ndarray]]:\n",
    "    processed_meshes = {}   \n",
    "    pbar = tqdm.tqdm(mesh_info_dict.items(), disable=not verbose)\n",
    "    for name, fields in pbar:\n",
    "        pbar.set_description(f\"Processing mesh: {name}\")\n",
    "        vertices, triangles = _load_and_process_mesh(fields['path'], scale=fields.get('scale', 1.0),\n",
    "                                                      invert_axis=fields.get('invert_axis', (False, False, False)), \n",
    "                                                      orient_by_centroid=fields.get('orient_by_centroid', False), \n",
    "                                                      return_as_numpy=True)\n",
    "        processed_meshes[name] = (vertices, triangles)\n",
    "    return processed_meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68bd5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldSegmentation:\n",
    "    def __init__(self, \n",
    "                 initial_params : Dict,\n",
    "                 vertices : np.ndarray, \n",
    "                 triangles : np.ndarray,\n",
    "                 exclude_boundary_loop : bool = True):\n",
    "        self.segmentation_params_types = {\n",
    "                    'min_H': float,\n",
    "                    'max_H': float,\n",
    "                    'use_pc2': bool,\n",
    "                    'pc2_quantile': float,\n",
    "                    'max_num_clusters': int,\n",
    "                    'expand_distance': float,\n",
    "                    'expand_graph_distance': int,\n",
    "                    'join_method': str,  # 'and' or 'or'\n",
    "                    }\n",
    "        self.vertices = vertices\n",
    "        self.triangles = triangles\n",
    "        self.vertex_normals = igl.per_vertex_normals(vertices, triangles)\n",
    "        principal_curvatures = igl.principal_curvature(vertices, triangles)\n",
    "        self.vertex_pc1_values, self.vertex_pc2_values = principal_curvatures[2], principal_curvatures[3]\n",
    "        #self.vertex_mean_curvature = (self.vertex_pc1_values + self.vertex_pc2_values) / 2.0\n",
    "        cotmatrix = igl.cotmatrix(vertices, triangles)\n",
    "        massmatrix = igl.massmatrix(vertices, triangles, igl.MASSMATRIX_TYPE_VORONOI)\n",
    "        laplacian = sparse.linalg.inv(massmatrix) @ cotmatrix\n",
    "        self.vertex_mean_curvature = np.sum((laplacian @ vertices)*self.vertex_normals, axis=1)\n",
    "        self.boundary_loop = igl.boundary_loop(triangles)\n",
    "        if exclude_boundary_loop:\n",
    "            self.vertex_mean_curvature[self.boundary_loop] = np.nan\n",
    "            self.vertex_pc2_values[self.boundary_loop] = np.nan\n",
    "        self.vertex_adj_list = igl.adjacency_list(triangles)\n",
    "        self.adj_graph = nx.from_dict_of_lists({i: nbrs for i, nbrs in enumerate(self.vertex_adj_list)})\n",
    "        self.params = {}\n",
    "        for param_name, param_type in self.segmentation_params_types.items():\n",
    "            if param_name in initial_params:\n",
    "                if not isinstance(initial_params[param_name], param_type):\n",
    "                    raise ValueError(f\"Parameter {param_name} must be of type {param_type}.\")\n",
    "                self.params[param_name] = initial_params[param_name]\n",
    "            else:\n",
    "                raise ValueError(f\"Missing required parameter: {param_name}\")\n",
    "        self.tree = KDTree(self.vertices)\n",
    "        self._mean_curvature_mask = None\n",
    "        self._pc2_mask = None\n",
    "        self._clusters = None\n",
    "        self._expanded_clusters = None\n",
    "        #self._annotations = None\n",
    "\n",
    "    def update_parameter(self, param_name: str, param_value, invalidate_caches: bool = True) -> bool:\n",
    "        if param_name not in self.segmentation_params_types:\n",
    "            raise ValueError(f\"Unknown parameter: {param_name}\")\n",
    "        if not isinstance(param_value, self.segmentation_params_types[param_name]):\n",
    "            raise ValueError(f\"Parameter {param_name} must be of type {self.segmentation_params_types[param_name]}.\")\n",
    "        old_value = self.params[param_name]\n",
    "        self.params[param_name] = param_value\n",
    "        parameter_changed = old_value != param_value\n",
    "        if invalidate_caches and parameter_changed:\n",
    "            if param_name in ['min_H', 'max_H']:\n",
    "                self._mean_curvature_mask = None\n",
    "                self._clusters = None\n",
    "            if param_name in ['use_pc2', 'pc2_quantile']:\n",
    "                self._pc2_mask = None\n",
    "                self._clusters = None\n",
    "            if param_name in ['max_num_clusters']:\n",
    "                self._clusters = None\n",
    "            if param_name in ['expand_distance', 'expand_graph_distance', 'join_method']:\n",
    "                self._expanded_clusters = None\n",
    "        return parameter_changed\n",
    "\n",
    "    def _get_mean_curvature_mask(self):\n",
    "        if self._mean_curvature_mask is None:\n",
    "            self._mean_curvature_mask = (self.vertex_mean_curvature >= self.params['min_H']) & (self.vertex_mean_curvature <= self.params['max_H'])\n",
    "        return self._mean_curvature_mask\n",
    "    def _get_pc2_mask(self):\n",
    "        if self._pc2_mask is None:\n",
    "            if self.params['use_pc2']:\n",
    "                pc2_threshold = np.nanquantile(self.vertex_pc2_values, self.params['pc2_quantile'])\n",
    "                self._pc2_mask = self.vertex_pc2_values >= pc2_threshold\n",
    "            else:\n",
    "                self._pc2_mask = None\n",
    "        return self._pc2_mask\n",
    "    \n",
    "    def _compute_clusters(self):\n",
    "        if self._clusters is None:\n",
    "            mean_curvature_mask = self._get_mean_curvature_mask()\n",
    "            pc2_mask = self._get_pc2_mask()\n",
    "            if pc2_mask is not None:\n",
    "                combined_mask = mean_curvature_mask & pc2_mask\n",
    "            else:\n",
    "                combined_mask = mean_curvature_mask\n",
    "            subgraph = self.adj_graph.subgraph(np.argwhere(combined_mask).flatten())\n",
    "            sorted_components = sorted(list(nx.connected_components(subgraph)), key=lambda x: len(x), reverse=True)\n",
    "            if self.params['max_num_clusters'] is None or self.params['max_num_clusters'] == 0:\n",
    "                raise ValueError(\"Parameter 'max_num_clusters' must be a positive integer.\")\n",
    "            sorted_components = sorted_components[:self.params['max_num_clusters']]\n",
    "            self._clusters = [ np.array(list(comp)) for comp in  sorted_components ]\n",
    "        return self._clusters\n",
    "    \n",
    "    @staticmethod\n",
    "    def _expand_nodes(graph : nx.Graph, nodes, dist : int):\n",
    "        if dist <= 0:\n",
    "            return set(nodes)\n",
    "        inflated = set(nodes)\n",
    "        frontier = set(nodes)\n",
    "        for _ in range(dist):\n",
    "            next_frontier = set()\n",
    "            for node in frontier:\n",
    "                next_frontier.update(graph.neighbors(node))\n",
    "            next_frontier -= inflated\n",
    "            inflated.update(next_frontier)\n",
    "            frontier = next_frontier\n",
    "            if not frontier:\n",
    "                break\n",
    "        return inflated\n",
    "\n",
    "    def _expand_clusters(self):\n",
    "        clusters = self._compute_clusters()\n",
    "        if self._expanded_clusters is None:\n",
    "            self._expanded_clusters = []\n",
    "            for cluster in clusters:\n",
    "                \n",
    "                grown_cluster_by_distance = None\n",
    "                grown_cluster_by_graph_distance = None\n",
    "                if self.params['expand_distance'] > 0:\n",
    "                    grown_cluster_by_distance = set(cluster)\n",
    "                    indices = self.tree.query_ball_point(self.vertices[cluster], r=self.params['expand_distance'])\n",
    "                    for nearby_indices in indices:\n",
    "                        grown_cluster_by_distance.update(nearby_indices)\n",
    "                if self.params['expand_graph_distance'] > 0:\n",
    "                    grown_cluster_by_graph_distance = self._expand_nodes(self.adj_graph, cluster, self.params['expand_graph_distance'])\n",
    "\n",
    "                if self.params['join_method'] == 'and':\n",
    "                    if grown_cluster_by_distance is not None and grown_cluster_by_graph_distance is not None:\n",
    "                        final_cluster = grown_cluster_by_distance.intersection(grown_cluster_by_graph_distance)\n",
    "                    elif grown_cluster_by_distance is not None:\n",
    "                        final_cluster = grown_cluster_by_distance\n",
    "                    elif grown_cluster_by_graph_distance is not None:\n",
    "                        final_cluster = grown_cluster_by_graph_distance\n",
    "                    else:\n",
    "                        final_cluster = set(cluster)\n",
    "                elif self.params['join_method'] == 'or':\n",
    "                    final_cluster = set(cluster)\n",
    "                    if grown_cluster_by_distance is not None:\n",
    "                        final_cluster.update(grown_cluster_by_distance)\n",
    "                    if grown_cluster_by_graph_distance is not None:\n",
    "                        final_cluster.update(grown_cluster_by_graph_distance)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown join_method: {self.params['join_method']}\")\n",
    "                self._expanded_clusters.append(np.array(list(final_cluster)))\n",
    "            self._expanded_clusters = self._expanded_clusters\n",
    "        return self._expanded_clusters\n",
    "    \n",
    "    def run(self):\n",
    "        return self._expand_clusters()\n",
    "def save_segmentation(segmentation : FoldSegmentation, clusters_annotations : Optional[List[str]] = None, include_geometry :  bool = True, include_curvatures : True = True) -> Dict:\n",
    "    if segmentation._clusters is None or segmentation._expanded_clusters is None:\n",
    "        raise ValueError(\"No clusters to export. Please run the segmentation first.\")\n",
    "    segmentation_dict = {}\n",
    "    segmentation_dict['params'] = segmentation.params\n",
    "    if include_geometry:\n",
    "        segmentation_dict['vertices'] = segmentation.vertices\n",
    "        segmentation_dict['triangles'] = segmentation.triangles\n",
    "    if include_curvatures:\n",
    "        segmentation_dict['vertex_mean_curvature'] = segmentation.vertex_mean_curvature\n",
    "        segmentation_dict['vertex_pc1_values'] = segmentation.vertex_pc1_values\n",
    "        segmentation_dict['vertex_pc2_values'] = segmentation.vertex_pc2_values\n",
    "\n",
    "    if clusters_annotations is not None:\n",
    "        annotations_dict = {}\n",
    "        annotation_counter = 0\n",
    "        for annotation in clusters_annotations:\n",
    "            name = None\n",
    "            clusters = None\n",
    "            if ':' in annotation:\n",
    "                sub_annotations = annotation.split(':')\n",
    "                if len(sub_annotations) == 2:\n",
    "                    name, clusters = sub_annotations\n",
    "            else:\n",
    "                clusters = annotation\n",
    "            if name is None:\n",
    "                name = \"annotation\" + str(annotation_counter)\n",
    "            if '+' in clusters:\n",
    "                clusters = clusters.split('+')\n",
    "                clusters = [int(c) for c in clusters]\n",
    "            else:\n",
    "                clusters = [int(clusters)]\n",
    "            annotations_dict[name] = np.unique(np.concatenate([segmentation._expanded_clusters[c] for c in clusters if c < len(segmentation._expanded_clusters)]))\n",
    "            annotation_counter += 1\n",
    "        segmentation_dict['segmentations'] = annotations_dict\n",
    "        segmentation_dict['annotations'] = clusters_annotations\n",
    "    return segmentation_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad12b9af",
   "metadata": {},
   "source": [
    "## Load Meshes\n",
    "Meshes are loaded from a dict. The dict must contain an entry per mesh with an arbitrary name. Each entry must be a dict with at least a 'path' field, containing the path of the mesh.\n",
    "We also accept other fields in each mesh dictionary.\n",
    "The 'scale' key contains either a single float or a 3-tuple of floats to scale the vertices with.\n",
    "The 'invert_axis' is a boolean 3-tuple which if set inverts each axis of the mesh as:\n",
    "$$ x' = x_{\\rm max} + x_{\\rm min} - x$$\n",
    "Below we also visualize the meshes using Plotly. At the moment, one can modify manually the meshes by specifying which axes to invert (as above). This results in a new 'mesh_info_dict'. Note: to avoid confusion, we do NOT use the original invert_axis field. In other words, this is useful when no prior 'invert_axis' field is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "915f9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/Users/schimmenti/Desktop/DresdenProjects/wingsurface/final_meshes/wildtype/\")\n",
    "#base_dir = Path(\"/data/biophys/schimmenti/Repositories/wingsurface/final_meshes/wildtype/\")\n",
    "mesh_info_dict = {p.stem: {'path': str(p.absolute())} for p in base_dir.glob(\"*.ply\")}\n",
    "mesh_info_dict = { key :   mesh_info_dict[key] for key in list(mesh_info_dict.keys())[:2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80696709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing mesh: 20210125_ecadGFPnbG4_upcrawling_disc2_scale0.5_fused_surface_blender_split: 100%|██████████| 2/2 [00:00<00:00,  5.85it/s]\n"
     ]
    }
   ],
   "source": [
    "mesh_dataset = load_and_process_meshes(mesh_info_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663c683",
   "metadata": {},
   "source": [
    "### View processed meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0051583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_axes_results = { name : mesh_info_dict[name].get('invert_axis', (False, False, False)) for name in mesh_dataset.keys() }\n",
    "def view_meshes():\n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(\n",
    "        title=\"\",\n",
    "        width=800, height=400,\n",
    "        scene=dict(\n",
    "            xaxis_title='x', yaxis_title='y', zaxis_title='z',\n",
    "            aspectmode='data',\n",
    "            uirevision=\"keep\"  # preserve camera/zoom\n",
    "        ),\n",
    "        margin=dict(l=50, r=50, t=60, b=0),\n",
    "        legend=dict(itemsizing='constant')\n",
    "    )\n",
    "    palette = px.colors.qualitative.T10\n",
    "    sample_id_widget = widgets.Dropdown(options=mesh_dataset.keys(), description='Sample')\n",
    "    close_button_widget = widgets.Button(description='Close')\n",
    "    tick_widgets = [widgets.Checkbox(description='Invert X'), \n",
    "                    widgets.Checkbox(description='Invert Y'), \n",
    "                    widgets.Checkbox(description='Invert Z')]\n",
    "    \n",
    "    ui = widgets.HBox([\n",
    "        sample_id_widget, *tick_widgets, close_button_widget])\n",
    "    def _replot():\n",
    "        fig.data = []\n",
    "        sample_id = sample_id_widget.value\n",
    "        vertices, triangles = mesh_dataset[sample_id]\n",
    "        mesh_trace = go.Mesh3d(\n",
    "            x=vertices[:, 0].max() + vertices[:, 0].min() - vertices[:, 0] if tick_widgets[0].value else vertices[:, 0],\n",
    "            y=vertices[:, 1].max() + vertices[:, 1].min() - vertices[:, 1] if tick_widgets[1].value else vertices[:, 1], \n",
    "            z=vertices[:, 2].max() + vertices[:, 2].min() - vertices[:, 2] if tick_widgets[2].value else vertices[:, 2],\n",
    "            i=triangles[:, 0],\n",
    "            j=triangles[:, 1],\n",
    "            k=triangles[:, 2],\n",
    "            color=palette[0],\n",
    "            opacity=0.5,\n",
    "            name='Mesh'\n",
    "        )\n",
    "        fig.add_trace(mesh_trace)\n",
    "\n",
    "    def on_tick_change(change):\n",
    "        invert_axes_results[sample_id_widget.value] = tuple(tick_widgets[i].value for i in range(3))\n",
    "        _replot()\n",
    "    \n",
    "    def _update_viewer(change):\n",
    "        if change is not None:\n",
    "            # we recover the previous settings\n",
    "            for i in range(3):\n",
    "                tick_widgets[i].unobserve_all()\n",
    "                tick_widgets[i].value = invert_axes_results[sample_id_widget.value][i]\n",
    "        for i in range(3):\n",
    "            tick_widgets[i].observe(on_tick_change, names='value')\n",
    "        \n",
    "        _replot()\n",
    "    \n",
    "    _update_viewer(None)\n",
    "    def on_sample_change(change):\n",
    "        _update_viewer(change)\n",
    "    sample_id_widget.observe(on_sample_change, names='value')\n",
    "    def on_close_button_clicked(b):\n",
    "        for _ in range(3):\n",
    "            invert_axes_results[sample_id_widget.value] = tuple(tick_widgets[i].value for i in range(3))\n",
    "        fig.close_all()\n",
    "    close_button_widget.on_click(on_close_button_clicked)\n",
    "    display(ui, fig)\n",
    "view_meshes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68873ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mesh_info_dict = {}\n",
    "for name, fields in mesh_info_dict.items():\n",
    "    new_fields = fields.copy()\n",
    "    new_fields['invert_axis'] = invert_axes_results[name]\n",
    "    new_mesh_info_dict[name] = new_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c524af1",
   "metadata": {},
   "source": [
    "## Segment folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4631900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_segmentations_folder = \"segmentations/\"\n",
    "saved_exported_segmentation_files = list(Path(saved_segmentations_folder).glob('*_segmentation.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56a722e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 20220517_ecadGFPnbG4_96hAEL_disc6_scale0.5_fused_surface_blender_split (found existing segmentation) :   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 20210125_ecadGFPnbG4_upcrawling_disc2_scale0.5_fused_surface_blender_split (found existing segmentation) : 100%|██████████| 2/2 [00:19<00:00,  9.64s/it]\n"
     ]
    }
   ],
   "source": [
    "use_existing_segmentations = True\n",
    "default_params_dict = {\n",
    "    'min_H': -1.0,\n",
    "    'max_H': -0.1,\n",
    "    'use_pc2': False,\n",
    "    'pc2_quantile': 0.0,\n",
    "    'max_num_clusters': 10,\n",
    "    'expand_distance': 5.0,\n",
    "    'expand_graph_distance': 0,\n",
    "    'join_method': 'or',\n",
    "}\n",
    "segmentation_results = {}\n",
    "annotation_results = {}\n",
    "pbar = tqdm.tqdm(mesh_info_dict.items())\n",
    "for name, fields in pbar:\n",
    "    old_file =[f for f in saved_exported_segmentation_files if f.stem == (name + \"_segmentation\")]\n",
    "    if len(old_file) == 1:\n",
    "        old_file = old_file[0]\n",
    "    else:\n",
    "        old_file = None\n",
    "    if old_file is not None and use_existing_segmentations is True:\n",
    "        pbar.set_description(f\"Loading {name} (found existing segmentation) \")\n",
    "        saved_segmentation = np.load(old_file, allow_pickle=True).item()\n",
    "        params = saved_segmentation.get('params', default_params_dict)\n",
    "        if 'annotations' in saved_segmentation:\n",
    "            annotation_results[name] = saved_segmentation['annotations']\n",
    "        else:\n",
    "            annotation_results[name] = []\n",
    "    else:\n",
    "        pbar.set_description(f\"Loading {name} \")\n",
    "        params = default_params_dict\n",
    "        annotation_results[name] = []\n",
    "    segmentation_results[name] = FoldSegmentation(params,\n",
    "                                                    vertices=mesh_dataset[name][0],\n",
    "                                                    triangles=mesh_dataset[name][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d8a93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 20220517_ecadGFPnbG4_96hAEL_disc6_scale0.5_fused_surface_blender_split\n",
      "Parameters: {'min_H': -1.0, 'max_H': -0.1, 'use_pc2': False, 'pc2_quantile': 0.0, 'max_num_clusters': 10, 'expand_distance': 0.0, 'expand_graph_distance': 5, 'join_method': 'or'}\n",
      "Number of clusters: 10\n",
      "Number of expanded clusters: 10\n",
      "Sample: 20210125_ecadGFPnbG4_upcrawling_disc2_scale0.5_fused_surface_blender_split\n",
      "Parameters: {'min_H': -1.0, 'max_H': -0.1, 'use_pc2': False, 'pc2_quantile': 0.0, 'max_num_clusters': 10, 'expand_distance': 0.0, 'expand_graph_distance': 5, 'join_method': 'or'}\n",
      "Number of clusters: 10\n",
      "Number of expanded clusters: 10\n"
     ]
    }
   ],
   "source": [
    "for name, seg in segmentation_results.items():\n",
    "    print(f\"Sample: {name}\")\n",
    "    print(f\"Parameters: {seg.params}\")\n",
    "    print(f\"Number of clusters: {len(seg._clusters) if seg._clusters is not None else 'Not computed'}\")\n",
    "    print(f\"Number of expanded clusters: {len(seg._expanded_clusters) if seg._expanded_clusters is not None else 'Not computed'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5854ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2de3fce3bb41678f46da96ff8b886c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(HBox(children=(Dropdown(description='Sample', options=('20220517_ecadGFPnbG4_96hAEL_d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def segment_folds(\n",
    "        curvature_step : float = 0.01,\n",
    "        quantile_step : float = 0.01,\n",
    "        distance_step : float = 0.1,\n",
    "):\n",
    "    fig = go.FigureWidget()\n",
    "    fig.update_layout(\n",
    "        title=\"\",\n",
    "        width=800, height=680,\n",
    "        scene=dict(\n",
    "            xaxis_title='x', yaxis_title='y', zaxis_title='z',\n",
    "            aspectmode='data',\n",
    "            uirevision=\"keep\"  # preserve camera/zoom\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "        legend=dict(itemsizing='constant')\n",
    "    )\n",
    "    fig.layout.legend.y = 0.5\n",
    "    palette = px.colors.qualitative.T10\n",
    "    sample_id_widget = widgets.Dropdown(options=[], description='Sample')\n",
    "    show_hide_clusters_widget = widgets.Checkbox(value=True, description='Show/Hide Clusters')\n",
    "    show_hide_curvature_widget = widgets.Checkbox(value=False, description='Show/Hide Curvature')\n",
    "    min_H_widget = widgets.FloatText(value=default_params_dict['min_H'], description='Min H', step=curvature_step)\n",
    "    max_H_widget = widgets.FloatText(value=default_params_dict['max_H'], description='Max H', step=curvature_step)\n",
    "    use_pc2_widget = widgets.Checkbox(value=default_params_dict['use_pc2'], description='Use PC2')\n",
    "    pc2_quantile_widget = widgets.BoundedFloatText(value=default_params_dict['pc2_quantile'], description='PC2 Quantile', step=quantile_step, min=0.0, max=1.0)\n",
    "    max_num_clusters_widget = widgets.BoundedIntText(value=default_params_dict['max_num_clusters'], description='Num Clusters', min=1)\n",
    "    expand_distance_widget = widgets.BoundedFloatText(value=default_params_dict['expand_distance'],  description='Expand Distance', step=distance_step, min=0.0)\n",
    "    expand_graph_distance_widget = widgets.BoundedIntText(value=default_params_dict['expand_graph_distance'], description='Expand Graph Distance', min=0)\n",
    "    join_method_widget = widgets.Dropdown(options=['and', 'or'], value=default_params_dict['join_method'], description='Join Method')\n",
    "    clusters_selection_widget = widgets.TagsInput(value=[],allow_duplicates=False)\n",
    "    close_button_widget = widgets.Button(description='Close')\n",
    "    row1_widget = widgets.HBox(\n",
    "        [sample_id_widget, widgets.HBox([ widgets.Label(\"Cluster IDs\", tooltip=\"Save cluster indices as comma-separated values, e.g. 0,2,5. You can merge clusters using '+', e.g. [0+1,2,5].\"),\n",
    "                                           clusters_selection_widget]), \n",
    "                                           close_button_widget],\n",
    "        layout=widgets.Layout(width=\"100%\", justify_content=\"space-between\", align_items=\"center\")\n",
    "    )\n",
    "    row2_left_widget = widgets.VBox([\n",
    "        show_hide_clusters_widget,\n",
    "        show_hide_curvature_widget,\n",
    "        min_H_widget, max_H_widget,\n",
    "        use_pc2_widget, pc2_quantile_widget,\n",
    "        max_num_clusters_widget,\n",
    "        expand_distance_widget,\n",
    "        expand_graph_distance_widget,\n",
    "        join_method_widget\n",
    "    ])\n",
    "    # Box is better than VBox for “just a figure”\n",
    "    row2_right_widget = widgets.Box(\n",
    "        [fig],\n",
    "        layout=widgets.Layout(width=\"100%\", height=\"100%\", overflow=\"visible\")\n",
    "    )\n",
    "    # -----------------------------\n",
    "    grid = widgets.GridspecLayout(2, 2, width=\"100%\", grid_gap=\"12px\")\n",
    "    grid[0, :] = row1_widget\n",
    "    grid[1, 0] = row2_left_widget\n",
    "    grid[1, 1] = row2_right_widget\n",
    "    grid.layout.grid_template_columns = \"320px 1fr\"\n",
    "    grid.layout.grid_template_rows = \"auto 1fr\"\n",
    "    grid.layout.align_items = \"flex-start\"\n",
    "    row2_left_widget.layout = widgets.Layout(\n",
    "        width=\"100%\",\n",
    "        height=\"680px\",\n",
    "        overflow_y=\"auto\",\n",
    "        overflow_x=\"hidden\",\n",
    "        align_self=\"flex-start\"\n",
    "    )\n",
    "    # -----------------------------\n",
    "    row2_right_widget.layout = widgets.Layout(\n",
    "        width=\"100%\",\n",
    "        height=\"680px\",\n",
    "        align_self=\"stretch\"\n",
    "    )\n",
    "    def _plot_mesh(delete_all):\n",
    "        if delete_all:\n",
    "            fig.data = []\n",
    "        else:\n",
    "            fig.data = tuple(t for t in fig.data if t.name != 'mesh')\n",
    "        sample_id = sample_id_widget.value\n",
    "        vertices, triangles = mesh_dataset[sample_id]\n",
    "        mesh_trace = go.Mesh3d(\n",
    "            x=vertices[:, 0],\n",
    "            y=vertices[:, 1], \n",
    "            z=vertices[:, 2],\n",
    "            i=triangles[:, 0],\n",
    "            j=triangles[:, 1],\n",
    "            k=triangles[:, 2],\n",
    "            color=palette[0],\n",
    "            opacity=0.5,\n",
    "            name='mesh'\n",
    "        )\n",
    "        if show_hide_curvature_widget.value:\n",
    "            mesh_trace.intensity = segmentation_results[sample_id].vertex_mean_curvature\n",
    "            mesh_trace.colorscale = 'RdBu'\n",
    "            mesh_trace.cmid = 0.0\n",
    "            mesh_trace.cmin, mesh_trace.cmax = np.nanquantile(segmentation_results[sample_id].vertex_mean_curvature, [0.05, 0.95])\n",
    "            mesh_trace.colorbar.x = 0.95\n",
    "            mesh_trace.colorbar.y = 0.5\n",
    "        else:\n",
    "            mesh_trace.intensity = None\n",
    "        fig.add_trace(mesh_trace)\n",
    "    def _show_hide_clusters(b):\n",
    "        for trace in fig.data:\n",
    "            if 'cluster' in trace.name:\n",
    "                if show_hide_clusters_widget.value:\n",
    "                    trace.visible = True\n",
    "                else:\n",
    "                    trace.visible = False    \n",
    "    def _plot_clusters():\n",
    "        name = sample_id_widget.value\n",
    "        segmentation = segmentation_results[name]\n",
    "        expanded_clusters = segmentation.run()\n",
    "        if len(fig.data) > 0:\n",
    "            fig.data = tuple(t for t in fig.data if 'cluster' not in t.name)\n",
    "        for i, exanded_cluster in enumerate(expanded_clusters):\n",
    "            cluster_trace = go.Scatter3d(\n",
    "                x=segmentation.vertices[exanded_cluster, 0],\n",
    "                y=segmentation.vertices[exanded_cluster, 1],\n",
    "                z=segmentation.vertices[exanded_cluster, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(size=2, color=palette[(i % (len(palette)-1)) + 1]),\n",
    "                name=f'cluster_{i}'\n",
    "            )\n",
    "            cluster_trace.visible = True if show_hide_clusters_widget.value else False\n",
    "            fig.add_trace(cluster_trace)   \n",
    "    def _on_parameter_change(change):\n",
    "        name = sample_id_widget.value\n",
    "        segmentation = segmentation_results[name]\n",
    "        segmentation.update_parameter('min_H', min_H_widget.value)\n",
    "        segmentation.update_parameter('max_H', max_H_widget.value)\n",
    "        segmentation.update_parameter('use_pc2', use_pc2_widget.value)\n",
    "        segmentation.update_parameter('pc2_quantile', pc2_quantile_widget.value)\n",
    "        segmentation.update_parameter('max_num_clusters', max_num_clusters_widget.value)\n",
    "        segmentation.update_parameter('expand_distance', expand_distance_widget.value)\n",
    "        segmentation.update_parameter('expand_graph_distance', expand_graph_distance_widget.value)\n",
    "        segmentation.update_parameter('join_method', join_method_widget.value)\n",
    "        \n",
    "        _plot_clusters()\n",
    "    def _on_annotation_change(change):\n",
    "        name = sample_id_widget.value\n",
    "        annotation_results[name] =  clusters_selection_widget.value\n",
    "    \n",
    "\n",
    "\n",
    "    def _on_sample_change(change):\n",
    "        name = sample_id_widget.value\n",
    "        segmentation = segmentation_results[name]\n",
    "        #show_hide_clusters_widget.value = True\n",
    "        #show_hide_curvature_widget.value = False\n",
    "        min_H_widget.value = segmentation.params['min_H']\n",
    "        max_H_widget.value = segmentation.params['max_H']\n",
    "        use_pc2_widget.value = segmentation.params['use_pc2']\n",
    "        pc2_quantile_widget.value = segmentation.params['pc2_quantile']\n",
    "        max_num_clusters_widget.value = segmentation.params['max_num_clusters']\n",
    "        expand_distance_widget.value = segmentation.params['expand_distance']\n",
    "        expand_graph_distance_widget.value = segmentation.params['expand_graph_distance']\n",
    "        join_method_widget.value = segmentation.params['join_method']\n",
    "        if name in annotation_results and annotation_results[name] is not None:\n",
    "            clusters_selection_widget.value = annotation_results[name]\n",
    "        else:                \n",
    "            clusters_selection_widget.value = []\n",
    "        _plot_mesh(True)\n",
    "        _plot_clusters()\n",
    "    sample_id_widget.observe(_on_sample_change, names='value')\n",
    "    sample_id_widget.options = list(mesh_dataset.keys())\n",
    "    sample_id_widget.value = list(mesh_dataset.keys())[0]\n",
    "    for widget in [min_H_widget, max_H_widget, use_pc2_widget, pc2_quantile_widget, max_num_clusters_widget,\n",
    "                   expand_distance_widget, expand_graph_distance_widget, join_method_widget]:\n",
    "        widget.observe(_on_parameter_change, names='value')\n",
    "\n",
    "    show_hide_clusters_widget.observe(_show_hide_clusters, names='value')\n",
    "    show_hide_curvature_widget.observe(lambda change: _plot_mesh(False), names='value')\n",
    "    clusters_selection_widget.observe(_on_annotation_change, names='value')\n",
    "    display(grid)\n",
    "segment_folds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf494c",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee115136",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, seg in segmentation_results.items():\n",
    "    clusters_annotations = annotation_results[name] if name in annotation_results else None\n",
    "    segmentation_dict = save_segmentation(seg, clusters_annotations=clusters_annotations, include_geometry=True, include_curvatures=True)\n",
    "    with open(f\"segmentations/{name}_segmentation.npy\", 'wb') as f:\n",
    "        np.save(f, segmentation_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flywings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
